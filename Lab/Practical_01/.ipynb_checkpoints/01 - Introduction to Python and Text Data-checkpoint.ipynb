{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R67NmC2GWaoR"
   },
   "source": [
    "# Text manipulation and extraction in Python\n",
    "\n",
    "This notebook introduces the basic operation on strings that can be done with the Python programming language.\n",
    "The notebook then focuses on text manipulation and extraction from different sources:\n",
    "- Text files\n",
    "- Web\n",
    "- PDF documents\n",
    "- OCR scanned PDF documents\n",
    "\n",
    "For an introduction or recap on Python, refer to the WeBeep page of this course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9fk15RybKqy"
   },
   "source": [
    "## Strings and lists\n",
    "\n",
    "A 'string' is simply a sequence of characters used to represent a document in a programming language such as Python.\n",
    "- Let's create a Python variable called 'doc' that contains a short document as a string.\n",
    "- After defining the variable, we repeat its name so as to print out its content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 531,
     "status": "ok",
     "timestamp": 1677006267697,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "XzuBscVnbKqz",
    "outputId": "b68dfe1c-f5a2-4251-b5fc-c8296b99249a"
   },
   "outputs": [],
   "source": [
    "doc = 'In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell'\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PILAgmKDbKqz"
   },
   "source": [
    "We can calculate the length of the string (in characters) by using the len() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 316,
     "status": "ok",
     "timestamp": 1677006270495,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "B0KzLRCjbKq0",
    "outputId": "a461e867-fd4f-4533-fd8f-b692af7346d9"
   },
   "outputs": [],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlH3zCkHbKq0"
   },
   "source": [
    "We can divide up the sentence into individual words by splitting it on whitespace (spaces, tabs, etc.). \n",
    "- This process is called 'tokenisation':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006272209,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "826CWmTnbKq0",
    "outputId": "f3c559a9-e839-42d7-ea36-045a3e17c34d"
   },
   "outputs": [],
   "source": [
    "doc.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Fky0cvtbKq0"
   },
   "source": [
    "Note that the ouptut above is in the form of comma-separated list of strings [s1,s2,...,sn]\n",
    "- The layout above is vertical, but if you use print() command you can get a more compact horizontal ouptut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1677006272772,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "UwTtRQIwbKq1",
    "outputId": "d3dbf5ff-a2c0-49ce-a328-f0997f0718e8"
   },
   "outputs": [],
   "source": [
    "print(doc.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7VvLRsobKq1"
   },
   "source": [
    "We didn't have to split the sentence on whitespace, we could have split it around any substring. \n",
    "- For example we could split on the comma ',' character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1677006273242,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "ahRXQem1bKq1",
    "outputId": "7ac1c4e4-64a8-47f2-8a6b-bcc39f12fb94"
   },
   "outputs": [],
   "source": [
    "doc.split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04A8J71QbKq1"
   },
   "source": [
    "How many words are there in the document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1677006273961,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "03XDB4C1bKq2",
    "outputId": "54f0bb30-9eff-46e7-a478-275c9fb48bdf"
   },
   "outputs": [],
   "source": [
    "words = doc.split()\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Bwb2-TTbKq2"
   },
   "source": [
    "Often in text-processing pipelines we convert all text to lower-case. \n",
    "- Since the sentence is almost all in lower-case already, let's convert it to upper-case instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006274360,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "-utEyCjZbKq2",
    "outputId": "f218c87b-723c-4e8a-9007-018f58c22635"
   },
   "outputs": [],
   "source": [
    "doc.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgR1MpJWbKq2"
   },
   "source": [
    "## Loading text from a file\n",
    "Let's now read in a longer document form a text file 'Alice_Chapter1.txt'\n",
    "\n",
    "- Make sure you have downloaded the file \"Alice_Chapter1.txt\" from the \"docs\" directory in the WeBeep directory where you found this notebook (I'd suggest you downlod the entire directory each time to be sure every file is in the right place).\n",
    "- If you are using Google Colab, you will then need to upload the file by clicking on the Folder icon to the left of the notebook, then clicking on the Upload icon, and finding the file on your drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1129,
     "status": "ok",
     "timestamp": 1677006546257,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "Zw9JB10EbKq2"
   },
   "outputs": [],
   "source": [
    "with open(\"docs/Alice_Chapter1.txt\") as f:\n",
    "    doc2 = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gPJhHrEbKq3"
   },
   "source": [
    "Print out the text as Python sees it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1677006549741,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "27CsU1gbbKq3",
    "outputId": "d3b95bc1-35ef-40bd-e3a3-83550944e81e"
   },
   "outputs": [],
   "source": [
    "doc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEDHeg0EbKq3"
   },
   "source": [
    "Note all the backslash characters '\\\\' in the text above.  \n",
    "- Python stores text as one big string (sequence of characters). \n",
    "- Special characters such as newlines and tabs are represented by '\\\\n' and '\\\\t' respectively.\n",
    "- The quote character is used to mark the start and end of the string ('string'), so quote characters that are present in the string are prefixed by a backslash to prevent the string from ending early ('str\\\\'ing'). \n",
    "- Using the print() command, we can output the string in a format that we're more used to seeing it in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1677006551233,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "3m9q8V4QbKq3",
    "outputId": "d3f0cbdc-0a43-47c2-dc10-885f461fc87e"
   },
   "outputs": [],
   "source": [
    "print(doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TiCwKJ_VbKq3"
   },
   "source": [
    "### Splitting lines and finding words\n",
    "\n",
    "We can split the text into separate lines using splitlines() method. \n",
    "- Since there are lot of lines, we'll only print the first 5 of them by appending `[:5]` to the name of the variable contianing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 540,
     "status": "ok",
     "timestamp": 1677006555810,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "aLyhzsTQbKq3",
    "outputId": "7aa53c8b-2317-49d4-df61-c8ea3dc289f6"
   },
   "outputs": [],
   "source": [
    "lines = doc2.splitlines()\n",
    "lines[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8AFF-WibKq4"
   },
   "source": [
    "Note that: \n",
    "- Some of the lines contain no text at all.\n",
    "- Some of the lines are surrounded by the double quote character \" becuase they contain the single quote character in the text. \n",
    "\n",
    "How many lines are there in total in the text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1677006560090,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "NfWU5HQhbKq4",
    "outputId": "bafe1780-5a05-47e6-f3e3-b7e91d901f72"
   },
   "outputs": [],
   "source": [
    "len(doc2.splitlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sD9FbeMnbKq4"
   },
   "source": [
    "We can search for a particular word in the text: \n",
    "- For example, let's search for the word 'Rabbit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1677006560665,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "oRAD91wXbKq4",
    "outputId": "ece6f2fb-20a8-42fe-b1e1-7c43863d990b"
   },
   "outputs": [],
   "source": [
    "doc2.find('Rabbit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZCPevxbbKq4"
   },
   "source": [
    "The number tells us that the word appears at the 552nd character position. \n",
    "\n",
    "We can format the output to state this explicitly:\n",
    "- We use the '+' command to concatenate strings, \n",
    "- and the str() command for converting an integer to a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1677006562735,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "6yT6aWipbKq4",
    "outputId": "94ddbf34-9d80-45ab-c00d-44ebf34912b4"
   },
   "outputs": [],
   "source": [
    "word = \"Rabbit\"\n",
    "mystring = f\"The word '{word}' appeared at character position {str(doc2.find(word))}in the text\"\n",
    "print(mystring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j34S1khxpIH3"
   },
   "source": [
    "What happens if we search for a string that does't exist in the document? \n",
    "- Try it... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1677006568329,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "LCrROJ69pCa_"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_1gK8GIbKq5"
   },
   "source": [
    "### Investigating the vocabulary of a document\n",
    "\n",
    "Now let's find the vocabulary of this text by: \n",
    "- first converting the text to lowercase\n",
    "- then splitting the words on whitespace\n",
    "- then selecting only distinct words by using the set() function\n",
    "\n",
    "Python sets are just regular sets from math where you can put heterogenous variables, only a single copy of each element is allowed in a set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1677006569627,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "5zkUbepNbKq5",
    "outputId": "62db7d12-b8f6-4eef-a56b-c3032e368dab"
   },
   "outputs": [],
   "source": [
    "lowercase_doc = doc2.lower()\n",
    "words = lowercase_doc.split()\n",
    "vocab = set(words)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FLXC6_vLbKq5"
   },
   "source": [
    "To make it easier to read, we could sort the vocabulary alphabetically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 911,
     "status": "ok",
     "timestamp": 1677006574407,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "Pc_XT1nBbKq5",
    "outputId": "ba78e74f-ed04-477b-d79f-d4a23bd1e2cc"
   },
   "outputs": [],
   "source": [
    "sorted_vocab = sorted(vocab)\n",
    "print(sorted_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4ZzLRipp5KE"
   },
   "source": [
    "That looks a bit weird. What are all those bracket '(' characters doing there? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIB-6xDabKq5"
   },
   "source": [
    "### Removing punctuation with a regular expression\n",
    "\n",
    "Notice that many of the vocabulary terms, particularly those at the start of the list, contain punctuation characters like quotes '\"', brackets '(' and exclamation marks '!'. We'll now see how to remove these puntuation characters:\n",
    "- First get a list of punctuation characters from the 'string' library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1677006574726,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "KCFQzseTbKq5",
    "outputId": "2819a6cc-1d7c-4b63-b182-c82994d949a4"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wct3c1EAbKq6"
   },
   "source": [
    "The list is provided as a single string. To convert it to a list of individual characters, just call the list function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006578578,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "TW-2BMVjbKq6",
    "outputId": "efff3186-f825-434f-a2af-9e117e327dc6"
   },
   "outputs": [],
   "source": [
    "list(string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxnuEuSjbKq6"
   },
   "source": [
    "Notice the double backslash character '\\\\\\\\' in the list. This is needed because backslash is used as the escape character. So if we don't put a double backslash, Python will interpret the single backslash as escaping the quote character that follows it.\n",
    "\n",
    "We can create a regular expression that will match any of those puncutation characters by simply surrounding the string of punctuation characters with square brackets: \"[]\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006579176,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "VSb8VgZrbKq6",
    "outputId": "6a192f28-69f9-4088-83da-0efa356798c9"
   },
   "outputs": [],
   "source": [
    "regex = '[' + string.punctuation + ']'\n",
    "print(regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJK_3gYDbKq6"
   },
   "source": [
    "We can use the new punctuation matching regular expression with the sub() command in the *re* (regular expression) libarary to remove the unwanted punctuation.\n",
    "- Note that the sub() routine actually performs a substitution each time it finds a match, but we will simply replace the punctuation character with an empty string: ''\n",
    "- Let's print out the first 1000 characters of the text after removing all punctuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1677006583038,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "LRYPdI3sbKq7",
    "outputId": "71cdf2c1-425a-4625-acdb-afe179bee72d"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "doc2_nopunctuation = re.sub(regex,'',doc2)\n",
    "print(doc2_nopunctuation[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDrmqJTbbKq7"
   },
   "source": [
    "Compare this output with the original text for the first 1000 characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1677006585753,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "A-7aO0mxbKq7",
    "outputId": "298e3d7d-0c2b-42af-e00f-54642cf752d4"
   },
   "outputs": [],
   "source": [
    "print(doc2[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBjg-w_pbKq7"
   },
   "source": [
    "Now that we've removed the punctuation, let's generate the sorted vocabulary again, by:\n",
    "- converting to lowercase\n",
    "- splitting on whitespace\n",
    "- select only distinct words\n",
    "- and sorting the words alphabetically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 565,
     "status": "ok",
     "timestamp": 1677006590564,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "apHh-4PQbKq7",
    "outputId": "0a4efed4-c101-4ce1-9817-edca893e4309"
   },
   "outputs": [],
   "source": [
    "words = doc2_nopunctuation.lower().split()\n",
    "sorted_vocab = sorted(set(words))\n",
    "print(sorted_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aY6icNSJbKq7"
   },
   "source": [
    "### Counting term frequencies\n",
    "\n",
    "We often represent documents by their vocbulary, and in particular by their most frequently occuring terms, since those words are most likely to describe well the topic of the document.\n",
    "- We can count the frequency of the terms in the document using the Counter() function from the NLTK (Natural Language Tool Kit) library. \n",
    "- A online book describing the functionality that the NLTK library provides is available here: http://www.nltk.org/book/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1677006590565,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "oJQwv6TpbKq8",
    "outputId": "3696b376-125e-453b-85d6-575c36ea187f"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "counts = nltk.Counter(words)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7_W-wMMbKq8"
   },
   "source": [
    "Note that the words are ordered according to their frequency. \n",
    "\n",
    "Lets display them again, but this time only the top 20, using the most_common() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1677006593713,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "_K5O9Jp7bKq8",
    "outputId": "3d5d91a9-76fb-4f3b-87bf-f696396d30fa"
   },
   "outputs": [],
   "source": [
    "counts.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CcxV1cjHbKq9"
   },
   "source": [
    "### Filtering Stopwords\n",
    "\n",
    "The most frequent terms: 'the', 'she', 'to', 'and', 'it', 'was', 'a', 'of', and 'i' aren't very interesting or descriptive of the story.\n",
    "- They are in fact frequent across *all documents* in the English language, and thus convey very little (if any) information about the topic of the document.\n",
    "- These terms are referred to as **'stop-words'**, because they can be removed from the description of the document without adversely affecting (indeed usually improving) the performance of a text search engine indexing the document.\n",
    "- The NLTK library contains lists of stop-word for English, Italian and many other languages. Let's print out the stop-word lists for English and Italian.\n",
    "\n",
    "Before we can get the stopword lists we need to download them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006602535,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "iDz79vDebKq9",
    "outputId": "ca47c109-0f73-4f7c-c5be-9fd45a3060c2"
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1542,
     "status": "ok",
     "timestamp": 1677006610695,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "MnWF6C-KbKq9",
    "outputId": "2abf61cc-f49f-401d-ef2a-5fcdd1512257"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print('English stopwords:')\n",
    "print(stopwords.words('english'))\n",
    "print()\n",
    "print('Italian stopwords:')\n",
    "print(stopwords.words('italian'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQ0U8qCnbKq9"
   },
   "source": [
    "Now let's remove the stop-words from the tokenised text before counting the frequency of the words in the document. \n",
    "- We can easily remove items from a list using some special syntax in Python: **[x for x in list1 if x not in list2]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006611950,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "qIHOmIwebKq9",
    "outputId": "ac549860-0732-4a3f-ca20-19b057ce2631"
   },
   "outputs": [],
   "source": [
    "words_nostopwords = [w for w in words if w not in stopwords.words('english')]\n",
    "counts_nostopwords = nltk.Counter(words_nostopwords)\n",
    "counts_nostopwords.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R24uBJ9VbKq-"
   },
   "source": [
    "These words look a little bit better ... \n",
    "- The words 'Alice', 'time', 'eat', 'door' and 'rabbit' might be useful for describing the document\n",
    "- but many of the other words, like 'little', 'like', 'could' and 'get', migh not be as useful.\n",
    "\n",
    "\n",
    "To get an even better list of words for describing the document we would need to make use of information about *how common each word is in general in the English language*, since the more common a particular word is, the less likely it is to be useful for describing the document. \n",
    "- More on that later in the course ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vu-ex9CDbKq-"
   },
   "source": [
    "## Downloading content from the Web\n",
    "\n",
    "One common source of text documents is the Web. Let's now download an article from Wikipedia, and then extract the text from it.\n",
    "\n",
    "First download the HTML page using the urllib library and print out just the first 2000 bytes of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006615662,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "u0BJs4iUbKq-",
    "outputId": "ec12bf54-93cf-424f-867a-4fe49fd7cf7f"
   },
   "outputs": [],
   "source": [
    "import urllib.request  \n",
    "html_doc = urllib.request.urlopen('https://en.wikipedia.org/wiki/Dune_(novel)').read()\n",
    "html_doc[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEroaWgRbKq-"
   },
   "source": [
    "Wow, that looks pretty ugly! \n",
    "\n",
    "Let's use another library (called Beautiful Soup) to parse the content of the page. \n",
    "- When printing out the parsed document we will use the prettify() method to indent all the HTML tags so that we can see the structure of the HTML document. (This is called 'pretty printing' in HTML/XML.)\n",
    "- Note that the printed output is very long, so after looking at it, you may want to edit the code to comment out the print line and re-run the cell. \n",
    " - To comment out the last line, simply place a hash character '#' in front of it: #print(parsed_doc.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 935,
     "status": "ok",
     "timestamp": 1677006617025,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "0oHjPDNxbKq-",
    "outputId": "16aff0d9-8449-4b9a-c093-54db68bab201",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bs4 as bs  \n",
    "parsed_doc = bs.BeautifulSoup(html_doc,'lxml')\n",
    "print(parsed_doc.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DniaRHMebKq_"
   },
   "source": [
    "### Extracting text from the HTML\n",
    "\n",
    "Now let's extract the text from the HTML page. \n",
    "- First find all paragraph \\<p\\> ... \\</p\\> elements within the HTML page.\n",
    "- The find_all() method returns a list of the elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006617026,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "Qetw2l_8bKq_"
   },
   "outputs": [],
   "source": [
    "paragraph_elements = parsed_doc.find_all('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GStEGbJrbKq_"
   },
   "source": [
    "Now print out the first of the paragraph elements to see what it looks like:\n",
    "- Note that Python starts counting from zero, not one, so the first element is: paragraph_elements[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1677006619410,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "chpj_uCTbKq_",
    "outputId": "6fc5d4ec-3181-4c41-dc8c-12ae133e8650"
   },
   "outputs": [],
   "source": [
    "print(paragraph_elements[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j88DzCBDbKq_",
    "tags": []
   },
   "source": [
    "Well that was pretty uninteresting. The first paragraph was empty!\n",
    "- Print out the second paragraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1677006620445,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "uG1QIZ2LbKq_",
    "outputId": "9ca81004-e66d-4b64-d77b-6c0aaa5bc299",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(paragraph_elements[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MaHrFocybKq_"
   },
   "source": [
    "OK, now let's get the text of each paragraph, without all of the HTML markup:\n",
    "- To do that we'll use the same python construct we saw before for iterating over the elements of a list.\n",
    "- This time though, we'll perform an operation on each element (extract the text) before returning the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006621796,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "FZ4e7kyVbKrA"
   },
   "outputs": [],
   "source": [
    "paragraph_texts = [p.text for p in paragraph_elements]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vcgx_IwAbKrA"
   },
   "source": [
    "Print out the second paragraph to see how it looks without all of the HTML tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1677006621797,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "cepBdE6ObKrA",
    "outputId": "171cf734-ae4a-4b75-d844-c520cd46c73c"
   },
   "outputs": [],
   "source": [
    "print(paragraph_texts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vSkaGgtxbKrA"
   },
   "source": [
    "Print out the whole list to see text from the entire document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1677006625707,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "O38oIsntbKrA",
    "outputId": "745fe74f-9be5-4ba1-addf-694a57294d73",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(paragraph_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLVjuK81bKrA"
   },
   "source": [
    "So there we have it, a list of paragraphs that have been extracted from a webpage.\n",
    "\n",
    "What shall we do with this text? \n",
    "- First let's join all the paragraphs together in a single string, separating them with a newline `\\n` character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 393,
     "status": "ok",
     "timestamp": 1677006625707,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "6LqUUP36bKrA",
    "outputId": "f25f3fab-7b3b-4804-84e3-8743d0512235",
    "tags": []
   },
   "outputs": [],
   "source": [
    "complete_text = '\\n'.join(paragraph_texts)\n",
    "print(complete_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zYoolZfobKrB"
   },
   "source": [
    "### Searching within extracted text\n",
    "\n",
    "Now that we have the text in a convenient format, we can start doing some analysis on the it. \n",
    "- We could search for somebody's name, e.g. the author 'Frank Herbert', by using the `search` command from the regular expression package 're' imported above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1677006626049,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "S-kI5ERqbKrB",
    "outputId": "663fb2bd-42c1-40d7-8b47-7c4dad306bd0"
   },
   "outputs": [],
   "source": [
    "re.search('Frank Herbert', complete_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Da5XgFHObKrB"
   },
   "source": [
    "This tells us that the author is first mentioned in between characters 256 and 269\n",
    "\n",
    "Let's find out how many times the director has been mentioned in the article. To do that we need to use the `findall()` command rather than search() command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006626347,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "FlE3ND0bbKrB",
    "outputId": "45989154-18d4-4487-fcf5-e72f69c79f9a"
   },
   "outputs": [],
   "source": [
    "name = 'Frank Herbert'\n",
    "matches = re.findall(name, complete_text)\n",
    "print(matches)\n",
    "print(f\"The name '{name}' occurs {len(matches)} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eM8y7KHxbKrB"
   },
   "source": [
    "More than just knowing that the author is being mentioned, we'd like to know what is being said about him. So we'd like to extract the sentences mentioning him. \n",
    "- We can do that by changing the regular expression that we are using to be more than just a string of keywords.\n",
    "\n",
    "The required regular expression is a little complicated, so let's build up to it slowly. \n",
    "- First let's write a simple expression to capture the first 10 characters immediately after his name. \n",
    "- In regular expressions, the dot character '.' is a wild-card that matches any character\n",
    "- so to match the next 10 characters, we can simply add ten dots to his name: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 293,
     "status": "ok",
     "timestamp": 1677006631400,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "06Y1SEXQbKrB",
    "outputId": "5af8203a-ae91-4eda-9110-235240763fea"
   },
   "outputs": [],
   "source": [
    "regex = name + '..........'\n",
    "print(f\"Regular expression: '{regex}'\")\n",
    "print(\"Returns:\")\n",
    "re.findall(regex, complete_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCZs2Aa0bKrB"
   },
   "source": [
    "That text window is far too short to be useful, and the regular expresssion is also particularly ugly. \n",
    "- Let's simplify regular expression by using the notation: `{n}` to repeat the previous character n times\n",
    "- and extend the window out to 100 characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1677006637321,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "frUSbdxabKrB",
    "outputId": "c922bfbd-2c87-434d-8e65-5a149a1be7a6"
   },
   "outputs": [],
   "source": [
    "regex = name + '.{100}'\n",
    "print(f\"Regular expression: '{regex}'\")\n",
    "print(\"Returns:\")\n",
    "re.findall(regex, complete_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ESWmmtAbKrB"
   },
   "source": [
    "Well the regular expression worked, but we lost one of the results because the required character window was too big. \n",
    "- A newline character was encountered less than 100 characters after the director's name.\n",
    "- To fix this, let's change the number of repetitions to be minimum zero, maximum 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 311,
     "status": "ok",
     "timestamp": 1677006651466,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "zrgXaV_ZbKrC",
    "outputId": "3d2d635b-7d02-476f-e1ef-1b45131914c4"
   },
   "outputs": [],
   "source": [
    "regex = name + '.{,100}'\n",
    "re.findall(regex, complete_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Rs0jgcPbKrC"
   },
   "source": [
    "OK, so that was fun, but what we'd really like to do is get the whole sentence around his name.\n",
    "- To do that we'll have to find all of the characters both before and after his name that do not include the period '.' character. \n",
    "- To choose any character except '.' we can write `[^.]` and to repeat that pattern zero or more times, we simply append '*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1677006656181,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "4NOpnAEebKrC",
    "outputId": "8a73ac41-4086-42a9-adb7-f7fdc14ad0e3"
   },
   "outputs": [],
   "source": [
    "regex = '[^.]*' + name + '[^.]*'\n",
    "re.findall(regex, complete_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beROSLPcbKrC"
   },
   "source": [
    "Finally, let's clean up the output a little: \n",
    "- by stripping off spaces and newline characters at the start of each sentence using the strip() method\n",
    "- and reappending the missing period at the end with `+ '.'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 299,
     "status": "ok",
     "timestamp": 1677006661455,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "dHg6gew9bKrC",
    "outputId": "3321ca11-9f74-4f81-d260-1884c3ec96dd"
   },
   "outputs": [],
   "source": [
    "name = 'Frank Herbert'\n",
    "regex = '[^.]*' + name + '[^.]*'\n",
    "matches = re.findall(regex, complete_text)\n",
    "[m.strip() + '.' for m in matches]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zM2VdMxWapN"
   },
   "source": [
    "## Combine data from multiple files\n",
    "\n",
    "In some cases data sets contain many different information, as a result the content is split into different files:\n",
    "- We can open the required files through Python\n",
    "- We can load the required information using dictionaries for fast search over the data set\n",
    "- We can merge the data sets into strings to obtan the final data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Hbz_3amWapN"
   },
   "source": [
    "### Loading files\n",
    "\n",
    "We are going to work with the [Cornell Movie--Dialogs Corpus](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html).\n",
    "You can download a copy of the original version of the corpus from this [link](http://www.mpi-sws.org/~cristian/data/cornell_movie_dialogs_corpus.zip).\n",
    "\n",
    "Extract the content of the zip archive and put it into a `docs/` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SHdFvy_WapN"
   },
   "source": [
    "There are two main files in the corpus:\n",
    "- `movie_lines.txt` is a text file where each row is an utterance in a dialogue, it contains all the lines avaialble in the corpus\n",
    "- `movie_conversations.txt` is a text file where each row contains the list with the identifiers of the lines composing a dialogue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVo6PAnMWapN"
   },
   "source": [
    "First we load the utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 950,
     "status": "ok",
     "timestamp": 1677006716234,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "xXDUxIoeWapO"
   },
   "outputs": [],
   "source": [
    "with open('docs/cornell movie-dialogs corpus/movie_lines.txt') as f:\n",
    "    lines = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPe2bTm6WapO"
   },
   "source": [
    "Let's see what data we have in each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 463,
     "status": "ok",
     "timestamp": 1677006720643,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "4Dr0KrGNWapO",
    "outputId": "d9d643c6-f4b5-4f7c-c50e-ce2dca348a58"
   },
   "outputs": [],
   "source": [
    "print(lines[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZgWvwiaWapO"
   },
   "source": [
    "There are three elements we want to keep:\n",
    "- line identifier\n",
    "- speaker\n",
    "- utterance text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCI__BaXWapO"
   },
   "source": [
    "Then we load the dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2578,
     "status": "ok",
     "timestamp": 1677006724391,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "20-CDIeCWapP"
   },
   "outputs": [],
   "source": [
    "with open('docs/cornell movie-dialogs corpus/movie_conversations.txt') as f:\n",
    "    lines_list = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8CDFb7OgWapP"
   },
   "source": [
    "Let's see what data we have in each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1677006726316,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "k10-S-NDWapP",
    "outputId": "ae0719bd-a377-4ce5-d6b1-26b39565580e"
   },
   "outputs": [],
   "source": [
    "print(lines_list[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfxzXx-0WapP"
   },
   "source": [
    "Here we are interested in keeping only the list of identifiers composing a dialogue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ryyyaJkWapP"
   },
   "source": [
    "### Parsing content with RegEx\n",
    "\n",
    "Now we can use RegEx to extract the useful information we want.\n",
    "\n",
    "With RegEx we can define the structure of an entire string or piece of string and we can group pieces of our expressions.\n",
    "In this way we can retreive specific pieces of a string that matches our request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "naZHebQGWapQ"
   },
   "source": [
    "Each row in the lines file follows the same pattern:\n",
    "1. Line identifier\n",
    "2. Speaker identifier\n",
    "3. Movie identifier\n",
    "4. Speaker\n",
    "5. Utterance text\n",
    "\n",
    "We are interested in 1, 2, and 5.\n",
    "\n",
    "Note that we have a peculiar separator between the elements `+++$+++`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfSaMUJ-WapQ"
   },
   "source": [
    "Let's write a RegEx first and apply it to the first rows.\n",
    "\n",
    "We use round brakets `()` to isolate groups (groups can be nested)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1677006731103,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "e4v_ZK56WapQ",
    "outputId": "dac86a6d-16a4-4471-8aea-55268ca54e00"
   },
   "outputs": [],
   "source": [
    "regex = '(L\\d+) \\+\\+\\+\\$\\+\\+\\+ u\\d+ \\+\\+\\+\\$\\+\\+\\+ m\\d+ \\+\\+\\+\\$\\+\\+\\+ ([\\w\\s]+) \\+\\+\\+\\$\\+\\+\\+ (.+)'\n",
    "print(f\"Regular expression: '{regex}'\")\n",
    "print(\"Returns:\")\n",
    "re.findall(regex, lines[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkUpqREqWapQ"
   },
   "source": [
    "What do you see in output?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wKLdQn8WapR"
   },
   "source": [
    "Now we can retrieve the desired information from each line and use it to build a list dictionaries where the keys are the IDs of the lines.\n",
    "\n",
    "Each element of the dictionary will contain the speaker and the uttered text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 454,
     "status": "ok",
     "timestamp": 1677006735061,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "1tHqch9nWapR"
   },
   "outputs": [],
   "source": [
    "lines = {key: {'speaker': sp, 'text': txt} for key, sp, txt in re.findall(regex, lines)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUpPJndGWapR"
   },
   "source": [
    "Now we can access the elements by specific names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1677006735061,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "3g-jEg5YWapR",
    "outputId": "c87220ec-83f4-4560-9e08-cf2facaaa2a4"
   },
   "outputs": [],
   "source": [
    "print(type(lines))\n",
    "print(lines['L868'])\n",
    "print(type(lines['L868']))\n",
    "print(lines['L867']['speaker'])\n",
    "print(lines['L867']['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bB_OozjfWapR"
   },
   "source": [
    "Now we can move to the dialogues file\n",
    "\n",
    "Each row in the dialogues file follows the same pattern:\n",
    "1. First speaker identifier\n",
    "2. Second speaker identifier\n",
    "3. Movie identifier\n",
    "4. List of lines identifier (expressed as a list of strings)\n",
    "\n",
    "We are interested only in 4.\n",
    "\n",
    "Note that we have again the peculiar separator between the elements `+++$+++`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5ygdmjoWapS"
   },
   "source": [
    "We split the search into two parts, first isolate the lists and then retrieve elements from the lists. Let's write a RegEx first and apply it to the first rows.\n",
    "\n",
    "**NOTE: this is not the smartest way to appraoch it, but it is useful to understand how regex work**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1677006736185,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "2NwvbOV5WapS",
    "outputId": "5b88cc26-df22-4326-8cf1-a8fd7aa1a20c"
   },
   "outputs": [],
   "source": [
    "list_regex = 'u\\d+ \\+\\+\\+\\$\\+\\+\\+ u\\d+ \\+\\+\\+\\$\\+\\+\\+ m\\d+ \\+\\+\\+\\$\\+\\+\\+ \\[(.+)\\]'\n",
    "print(f\"Regular expression: '{list_regex}'\")\n",
    "print(\"Returns:\")\n",
    "re.findall(list_regex, lines_list[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1ITZzv-WapS"
   },
   "source": [
    "Each element here is a string with the code of the line. We can search in each string separately the line IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1677006739427,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "7tqCn-3hWapS",
    "outputId": "162eebb5-a84e-4cf7-ba0e-36d1fe9c2580"
   },
   "outputs": [],
   "source": [
    "elem_regex = 'L\\d+'\n",
    "s = re.findall(list_regex, lines_list[:1000])[0]\n",
    "print(f\"Regular expression: '{elem_regex}'\")\n",
    "print(f\"String: \\\"{s}\\\"\")\n",
    "print(\"Returns:\")\n",
    "re.findall(elem_regex, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5jGDOQEPWapS"
   },
   "source": [
    "Now we are dealing with an actual list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006740476,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "v5yVCWVjWapT",
    "outputId": "1f78ef47-16ec-47b7-d1e0-df208c44c7b0"
   },
   "outputs": [],
   "source": [
    "print(type(re.findall(elem_regex, s)))\n",
    "print(type(re.findall(elem_regex, s)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eN3HPpl4WapT"
   },
   "source": [
    "Now we can retrieve the desired information from each line and use it to build a list, each element of the list is a list itself.\n",
    "The inner list contains the IDs of the lines composing the dialogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 516,
     "status": "ok",
     "timestamp": 1677006749430,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "1PV1s7CrWapT",
    "outputId": "e16b51fd-41e0-444a-a463-063834a9fbd5"
   },
   "outputs": [],
   "source": [
    "lines_list = [re.findall(elem_regex, s) for s in re.findall(list_regex, lines_list)]\n",
    "lines_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0v99m8vsWapT"
   },
   "source": [
    "### Composing the dialogues\n",
    "\n",
    "Now we have an indexed list of lines and a list of IDs composing a dialogue, we can finally put all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRdZRwK1WapU"
   },
   "source": [
    "For each dialogue in `lines_list` we compose a string with all the turns separated by a newline character.\n",
    "A turn is a speaker-text pair in the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 426,
     "status": "ok",
     "timestamp": 1677006753188,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "Oyw0V3u9WapU",
    "outputId": "d1b22380-4f34-449b-ca3d-945efb7e2dc5"
   },
   "outputs": [],
   "source": [
    "dialogues = [\n",
    "    '\\n'.join(f'{lines[idx][\"speaker\"]}: {lines[idx][\"text\"]}' for idx in indices) \n",
    "    for indices in lines_list if all(idx in lines for idx in indices)  # There are some missing \n",
    "]\n",
    "len(dialogues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adW8wds-WapU"
   },
   "source": [
    "We can give a look to one of the extracted dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006757457,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "EFiyNdDjWapU",
    "outputId": "ac2c56ff-88a4-41b3-99c1-a10625d70a43"
   },
   "outputs": [],
   "source": [
    "print(dialogues[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006758314,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "aH9T6tWNWapU",
    "outputId": "b0e88a7c-7c0a-4e8a-9a5a-19f763606584"
   },
   "outputs": [],
   "source": [
    "print(dialogues[2307])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzOu1jlTbKrC",
    "tags": []
   },
   "source": [
    "## Loading text from a PDF\n",
    "\n",
    "Much of the text on the internet is present inside PDF documents, and often we'd like to extract text from them. \n",
    "\n",
    "There are many different ways to do that in Python. Today we'll use the pdfplumber API: https://github.com/jsvine/pdfplumber\n",
    "- In order to use pdfplumber module, we first need to install it. \n",
    "- We can do that from inside the jupyter notebook by calling the pip3 command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3158,
     "status": "ok",
     "timestamp": 1677006844287,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "UQ_Q1rEPbKrC",
    "outputId": "567cd6b1-2950-4ebe-e12e-b76a9682660e"
   },
   "outputs": [],
   "source": [
    "!pip3 install pdfplumber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sic3jHSObKrC"
   },
   "source": [
    "Now we can import the module and use it to extract content from a PDF. \n",
    "- Let's try extracting content from this NLP reasearch paper: https://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf\n",
    "- The HTTPS server won't allow us direct programmatic access, so you'll need to use the file in the `docs/` directory on WeBeep where you found this notebook (as we did with the original Alice text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006849925,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "NN-4B_UIbKrD"
   },
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "filename = 'docs/collobert11a.pdf'\n",
    "pdf = pdfplumber.open(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C49W1ARdbKrD"
   },
   "source": [
    "How many pages are in the report? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 698,
     "status": "ok",
     "timestamp": 1677006854377,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "MzALGQywbKrD",
    "outputId": "33fe11de-29a9-420c-ffd0-2b28a582e9e5"
   },
   "outputs": [],
   "source": [
    "len(pdf.pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZXe04dobKrD"
   },
   "source": [
    "Wow, that's not a lot of pages!\n",
    "\n",
    "We can have a look at the first couple of pages extracting the text from them: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 732,
     "status": "ok",
     "timestamp": 1677006859781,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "nM4yYdfjbKrD",
    "outputId": "3ee6b819-87c0-4568-ffe7-6f3d55f420e8"
   },
   "outputs": [],
   "source": [
    "text = pdf.pages[0].extract_text(x_tolerance=1)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1677006864590,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "lXRuv5mibKrD",
    "outputId": "969a7a4a-cd57-431b-8450-54b630b693de"
   },
   "outputs": [],
   "source": [
    "text = pdf.pages[1].extract_text(x_tolerance=1)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5oNjvSm1bKrD"
   },
   "source": [
    "Extract the text from all the pages of the document into a list\n",
    "- Note: this might take a minute. There are a lot of pages ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8181,
     "status": "ok",
     "timestamp": 1677006880830,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "xCuTTuvSbKrD"
   },
   "outputs": [],
   "source": [
    "texts = [page.extract_text(x_tolerance=1) for page in pdf.pages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFdEPAa0bKrD"
   },
   "source": [
    "Now concatenate all the text together into a single string. \n",
    "- We'll separate them from one another using a couple of newline characters and some spaces too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1677006880831,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "VA2Je3JpbKrE",
    "outputId": "5f8cb7e6-61cd-48a2-e109-40c1d828e885",
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"  \\n\\n\".join(texts)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8XeouXkbKrE"
   },
   "source": [
    "#### Using Regular Expressions to search PDF \n",
    "\n",
    "Use some regular expressions to search through the text for some interesting content. \n",
    "- You could look for email addresses, phone numbers, addresses, ...\n",
    "- Let's try first to look for email addresses: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 310,
     "status": "ok",
     "timestamp": 1677006935956,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "nXMhf0aNbKrE",
    "outputId": "e9c96737-0d56-456f-8bc6-5dd9239b6043"
   },
   "outputs": [],
   "source": [
    "regex = '[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "emails = re.findall(regex,text)\n",
    "print(emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqzxkQ28bKrE"
   },
   "source": [
    "Did you find any? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5XPlU-1WapY"
   },
   "source": [
    "POS, Chunking, NER, and SRL are all NLP tasks. \n",
    "- Are they mentioned anywhere in the paper? \n",
    "- Write a regular expression to find out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JabBh00YbKrE"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-eWNcQbbKrE"
   },
   "source": [
    "Other ideas to try:\n",
    "- In this period reaserchers started using neural networks to solve NLP. Find out where neural networks are mentioned in the report and in what context.\n",
    "- Theauthors use a data set composed of text coming from the Wall Street Journal (WSJ). Search for references to it in the PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UPGXsTFFbKrE"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBR_N4eQbKrE"
   },
   "source": [
    "Load another PDF and write regular expressions to search for content in it. \n",
    "- For example, you can find reports for Ferrari here: https://corporate.ferrari.com/en/investors/results/reports\n",
    "- Let's load an interim report from September 2020 (you can find it in the same `docs` folder as before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13504,
     "status": "ok",
     "timestamp": 1677006961536,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "zzSw45EtbKrF",
    "outputId": "0d5aacda-56a1-407d-8290-8397ce35bb3a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = 'docs/ferrari_interim_report_at_and_for_the_three_and_nine_months_ended_september_30_2020.pdf'\n",
    "pdf = pdfplumber.open(filename)\n",
    "text = '\\n\\n'.join([page.extract_text() for page in pdf.pages])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nd8hAX4aV0JK"
   },
   "source": [
    "### Extracting Tables from a PDF \n",
    "\n",
    "Sometimes it can be useful to extract tabular data from a PDF. \n",
    "- Tools exist that allow you to do this programmatically, making the extraction process semi-automatic.\n",
    "- One tool that can do this is the *tabula* library. Let's install it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5602,
     "status": "ok",
     "timestamp": 1677006978213,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "3_rwPuYmGCVc",
    "outputId": "8b047957-0a6e-4662-8a99-237523fccb58"
   },
   "outputs": [],
   "source": [
    "!pip install tabula-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "naFDi4yNWyY9"
   },
   "source": [
    "Now we can use *tabula* to extract all the tables from Ferrari's interim report above: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 25205,
     "status": "ok",
     "timestamp": 1677007010328,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "-pQwzInjG8Rt"
   },
   "outputs": [],
   "source": [
    "import tabula \n",
    "tables = tabula.read_pdf(filename, pages=\"all\", multiple_tables=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNrQUIGrX6Rn"
   },
   "source": [
    "Let's have a look at some of the tables produced\n",
    "- the first table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "executionInfo": {
     "elapsed": 316,
     "status": "ok",
     "timestamp": 1677007016242,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "86E4O5vDH8Hq",
    "outputId": "81a7b76c-643b-4be8-b9b1-e9fba57fbd08"
   },
   "outputs": [],
   "source": [
    "tables[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXPN-2SDYCao"
   },
   "source": [
    "- the third table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "executionInfo": {
     "elapsed": 344,
     "status": "ok",
     "timestamp": 1677007029888,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "4fOAuloxYKvp",
    "outputId": "6866188f-a006-4b77-ad30-aa52b1d3c4af"
   },
   "outputs": [],
   "source": [
    "tables[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDCG8UeAYbwM"
   },
   "source": [
    "It can be seen that the tables are in need of a bit of cleaning to make them usable. \n",
    "- The tables are Pandas dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1677007054244,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "GWqHAlmoJSaS",
    "outputId": "ae0e53c2-47ae-4253-cb35-0c351b28bfbe"
   },
   "outputs": [],
   "source": [
    "type(tables[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "reWHSqBOYwcU"
   },
   "source": [
    "So we can clean-up the table by:\n",
    "- dropping some columns\n",
    "- dropping some rows\n",
    "- renaming the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1677007059263,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "YlpIdJI0Jt-n",
    "outputId": "9060daa1-f1c4-44cc-911a-86e93261952f"
   },
   "outputs": [],
   "source": [
    "df = tables[0]\n",
    "df = df.drop(df.columns[[1,5]], axis=1)  # drop columns: 1,5\n",
    "df = df.drop([0,5,12])                   # drop rows: 0,5,12\n",
    "df = df.reset_index(drop=True)           # reset index\n",
    "df.columns = ('Field','3months_to_30092020','3months_to_30092019','9months_to_30092020','9months_to_30092019') # rename columns\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUsE_YcMbjZ_"
   },
   "source": [
    "During the cleaning phase, some of the values may need to be updated too (e.g. certain values in the Field column above).\n",
    "- Ideally the above cleaning operations would be done automatically.\n",
    "- In practice, tables have lots of nested structure (including the one we just extracted), \n",
    "- and it's still a hard research problem to do the cleaning reliably, (particularly the generation of the column names that we provided manually).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Udj4WngyWapb"
   },
   "source": [
    "## Loading text from scanned document\n",
    "\n",
    "But what if my documents have been scanned? \n",
    "- In that case the task of extracting text from them is much more difficult.\n",
    "\n",
    "It is possible to extract text also from images, but you will need to have an Optical Character Recognition (OCR) system installed. \n",
    "We can use a combination of layout parsing and OCR to extract the text.\n",
    "- Layout parser is an opensource library to detect leyoutis in images: https://towardsdatascience.com/analyzing-document-layout-with-layoutparser-ed24d85f1d44\n",
    "- Tesseract is an opensource OCR system provided by Google. Some systems (such as Linux) come with Tesseract pre-installed. Others need to install it from here: https://tesseract-ocr.github.io/tessdoc/Home.html \n",
    "- If you have Tesseract installed, you can follow the instructions here to use it from Python: https://towardsdatascience.com/extracting-text-from-scanned-pdf-using-pytesseract-open-cv-cd670ee38052\n",
    "\n",
    "Give a look at the first link to see how it works, and try it yourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GzsfKKdGe2wd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
