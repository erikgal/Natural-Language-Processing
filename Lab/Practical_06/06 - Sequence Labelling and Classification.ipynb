{"cells":[{"cell_type":"markdown","metadata":{"id":"giKsby3Lpdlp"},"source":["# Sequence Labelling and Classification\n","\n","In this session we'll first investigate Part-of-Speech (POS) tagging and Named-entity recognition (NER). \n","- For this we will make use of the spaCy natural langauge processing API: https://spacy.io/\n","- spaCy is an opensource API that provides state-of-the-art performance on sequence labeling tasks such as POS tagging and NER. \n","- Parts of this tutorial are based on code from: https://towardsdatascience.com/named-entity-recognition-with-nltk-and-spacy-8c4a7d88e7da\n","\n","In the second part of the tutorial we will train a Text classifier that makes use of a Bidirectional LSTM (Long Short-term Memory) model.\n"]},{"cell_type":"markdown","metadata":{"id":"0OgRPEb6pdlv"},"source":["## Installing spaCy and downloading models\n","\n","First we need to check whether the spaCy library is installed:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6875,"status":"ok","timestamp":1680621240579,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"3083U81cpdlv","outputId":"37c2e12f-f470-44c5-a8aa-288c6f4bf61c"},"outputs":[],"source":["!pip install -U spacy"]},{"cell_type":"markdown","metadata":{"id":"CJ1xLIcHpdlw"},"source":["Then we need to download pretrained models for use with spaCy. We will load models for both English and Italian:\n","- The models are called 'en_core_web_sm' and 'it_core_news_sm', where the 'web'/'news' indicates what type of collection the model was trained on and the 'sm' at the end indicates that we are using the 'small' version of the models\n","- Other models are available here: https://spacy.io/models\n","- The following code calls the python executable instructing it to run the module 'spacy', which in turn download the models. See discussion here: https://stackoverflow.com/questions/46148033/unable-to-load-en-from-spacy-in-jupyter-notebook"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44108,"status":"ok","timestamp":1680621284673,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"dyv-NpFbpdlw","outputId":"6bc10957-cf53-4fe8-d0ed-06adbe16403f"},"outputs":[],"source":["import sys\n","!{sys.executable} -m spacy download en_core_web_sm\n","!{sys.executable} -m spacy download it_core_news_sm;"]},{"cell_type":"markdown","metadata":{"id":"yYRlbtvspdlx"},"source":["We are now ready to import spacy and load a model. Let's start with the English model:"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4054,"status":"ok","timestamp":1680621288705,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"4KHrsza0pdlx"},"outputs":[],"source":["import spacy\n","import en_core_web_sm\n","nlp_model = en_core_web_sm.load()"]},{"cell_type":"markdown","metadata":{"id":"jy4K8dRApdlx"},"source":["Consider the following piece of text:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":71,"status":"ok","timestamp":1680621288706,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"3MGjLJU0pdlx","outputId":"78f14c0f-8d93-4a25-e331-f64eb887794b"},"outputs":[],"source":["text = 'Melbourne is to re-enter Stage 3 lockdown after a record increase in cases. Victorian state premier Daniel Andrews said there was “simply no alternative” to reimposing stay at home restrictions in Australia’s second-biggest city.'\n","text = \"Good evening, London. Allow me first to apologize for this interruption. I do, like many of you, appreciate the comforts of everyday routine, the security of the familiar, the tranquillity of repetition. I enjoy them as much as any bloke. But in the spirit of commemoration, whereby those important events of the past, usually associated with someone's death or the end of some awful bloody struggle, are celebrated with a nice holiday, I thought we could mark this November the fifth, a day that is sadly no longer remembered, by taking some time out of our daily lives to sit down and have a little chat.\"\n","print(text)"]},{"cell_type":"markdown","metadata":{"id":"h_rCI0Hbpdly"},"source":["Parse the text using the NLP engine:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":67,"status":"ok","timestamp":1680621288706,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"xmpvXvjapdly","outputId":"88975cdf-381b-4d35-a102-25406e1360e4"},"outputs":[],"source":["parsed_text = nlp_model(text)\n","print(parsed_text)"]},{"cell_type":"markdown","metadata":{"id":"nnXyGOx0pdlz"},"source":["Did it do something? It looks like it has just output the same text.\n","- Actually, yes. It has parsed the input and built its internal datastructure from it. \n","- Note that the length of the parsed object is in words, not characters:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52,"status":"ok","timestamp":1680621288707,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"fbAOI2Mnpdlz","outputId":"c862b4f7-295f-435b-ea4f-9e5e1838de6f"},"outputs":[],"source":["print(f'The length of the original text is {len(text)} chacacters')\n","print(f'The length of the parsed text is {len(parsed_text)} words')"]},{"cell_type":"markdown","metadata":{"id":"xImJ-i_Lpdlz"},"source":["## Part-of-Speech Tagging\n","\n","While parsing the text, spaCy performs part-of-speech (POS) tagging. \n","- We can see the POS tag for each token as follows:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1680621288707,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"Ho4HEJTLpdlz","outputId":"03d77116-255b-4728-beb0-14e6eef297d7"},"outputs":[],"source":["[(w,w.pos_) for w in parsed_text]"]},{"cell_type":"markdown","metadata":{"id":"YFEzvleepdlz"},"source":["Who remembers their grammar from high school? What do all those POS symbols mean?\n","- You can find an explanation of the POS tags on this website https://spacy.io/api/annotation in the section \"Universal Part-of-speech Tags\" \n","\n","What can we do with POS tags? \n","- Well, we could select all terms that have a certain tag, such as all adjectives:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1680621288708,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"6Kcjc28lpdl0","outputId":"f2bce382-6fd3-48f2-a708-1299c87fe5e6"},"outputs":[],"source":["set(w for w in parsed_text if w.pos_=='ADJ')"]},{"cell_type":"markdown","metadata":{"id":"ftw5HEYEpdl0"},"source":["That was a little underwhelming. \n","- Let's try it on Alice in Wonderland chapter 1 text. (You'll need to upload it again to Google Colab)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1016,"status":"ok","timestamp":1680621289713,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"tGRt3HF8pdl0","outputId":"4982319d-13f7-4035-a973-efe02b36054e"},"outputs":[],"source":["adjectives = sorted(set(w.text for w in nlp_model(open(\"docs/Alice_Chapter1.txt\", \"r\").read()) if w.pos_=='ADJ'))\n","print(adjectives)"]},{"cell_type":"markdown","metadata":{"id":"Pct1jNdEpdl0"},"source":["You can see how descriptive a writer Lewis Carroll was! \n","\n","This leads us to one explanation as to why we might want to extract POS tags from text: \n","- They can sometimes be useful for **extracting features** (often handcrafted ones) for certain text classification tasks (such as authorship identification).\n","- This is particularly the case if only a small amount of training data is available.  \n","- For example, in this article (https://towardsdatascience.com/automatically-detect-covid-19-misinformation-f7ceca1dc1c7) hand-crafted features are extracted for classifying covid misinformation. \n","\n","Another reason why we might consider POS tagging is to **reduce ambiguity** in our bag-of-words representation by appending POS tags to word occurrences. \n","- Consider the following two sentences:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46,"status":"ok","timestamp":1680621289713,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"2iO992Q-pdl0","outputId":"58971e41-f54b-4c82-97ec-0713d4038d2f"},"outputs":[],"source":["ex1 = 'I catch the train to and from work.'       # This is Prof. Mark Carman speaking\n","ex2 = 'I like to train at least 6 times a week.'  # This is Prof. Jacked Carman speaking\n","\n","print(ex1, '     <-- \\'train\\' is a', nlp_model(ex1)[3].pos_)\n","print(ex2, '<-- \\'train\\' is a', nlp_model(ex2)[3].pos_)"]},{"cell_type":"markdown","metadata":{"id":"dHlqof06pdl1"},"source":["The second sentence has nothing to do with trains, despite containing the word 'train'!\n","- We could deal with this issue by appending the POS tag to the observed literal to form vocabulary elements: train_NOUN, train_VERB\n","\n","A final reason why we might think about running POS tagging would be to extract proper nouns from the text, since they refer to real entities that are being discussed in it:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1680621289714,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"kW4TbHffpdl1","outputId":"7e252df4-9ca4-42bc-fd53-e7eb32148ecf"},"outputs":[],"source":["[w.text for w in parsed_text if w.pos_=='PROPN']"]},{"cell_type":"markdown","metadata":{"id":"cDl1pPoSpdl1"},"source":["Shortly though, we will talk about Entity-extraction, which is the task of identifying and categorising the entities discussed in the text."]},{"cell_type":"markdown","metadata":{"id":"NDh0iS65pdl1"},"source":["## Lemmatization\n","\n","While parsing, spaCy also performs lemmatization. \n","- Lemmatization is the process of extracting the 'lemma' for each token, which is the canonical form of the word that would be found in the dictionary, (see https://en.wikipedia.org/wiki/Lemma_(morphology))\n","- Basically, verbs converted to their root form, e.g.: **went, going, goes, gone => go**\n","- And nouns are retuned to singular form: **kittens => kitten**\n","- Lemmatization is a more complicated POS-aware process than stemming (https://en.wikipedia.org/wiki/Stemming). Stemmers simply apply a set of language-specific syntax rules to recover the stem of the word"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1680621289714,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"EevBrQRbpdl1","outputId":"f7505a83-5248-4f32-d72c-94c0309ee832"},"outputs":[],"source":["[(x, x.lemma_) for x in parsed_text]"]},{"cell_type":"markdown","metadata":{"id":"IEIoq1RFpdl1"},"source":["Why would one want to perfom lemmatization? -- Or stemming for that matter?\n","- to **reduce the vocabulary size** and thereby generalise the representation. -- This used to be very important for improving performance of search engine performance (better similarity measures between documents) and also classifiers on small datasets, (before word embeddings came along).\n","- to **look-up information** about the word in a dictionary/ontology, such as WordNet (https://en.wikipedia.org/wiki/WordNet). This used to be an important way to compute semantic similarity between words, but again, word embeddngs probably do a better job."]},{"cell_type":"markdown","metadata":{"id":"4vBQ7f0tpdl2"},"source":["## Dependency Parsing\n","\n","Tradititonally in Natural Language Processing, text is processed in a pipeline that first tokenizes, then POS tags, lemmatizes and finaly dependency parses a piece of text. \n","- The idea with dependency parsing is to determine what function each of the word instances is fulfilling in the sentence. \n","- What is the subject and object of the sentence? \n","- Which noun is each adjective referring to?\n","\n","So while parsing the text, the spaCy model also generates a **dependency parse tree**, which can be displayed using 'displacy':"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":880},"executionInfo":{"elapsed":389,"status":"ok","timestamp":1680621342780,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"Dbz57hc5pdl2","outputId":"b24c271f-b283-40d2-af3d-4d61dadd02ca"},"outputs":[],"source":["from spacy import displacy\n","displacy.render(parsed_text, jupyter=True, style='dep')"]},{"cell_type":"markdown","metadata":{"id":"quwWOjbOpdl3"},"source":["Such dependency trees are interesting for understanding and visualising language (particularly for linguists) and could possibly be used for some downstream tasks (say checking ambiguity in legal documents).  \n","\n","Consider the sentences:\n","- *The girl saw a man carrying a telescope.*\n","- *The girl saw a man with a telescope.*\n","\n","Who had the telescope?"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":354},"executionInfo":{"elapsed":397,"status":"ok","timestamp":1680621349473,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"_AxJLNswpdl3","outputId":"ea6c38ac-eec4-42a7-d30b-518f75925dec"},"outputs":[],"source":["displacy.render(nlp_model('The girl saw a man carrying a telescope.'),jupyter=True,style='dep')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":354},"executionInfo":{"elapsed":69,"status":"ok","timestamp":1680621351529,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"7abgGOdwpdl3","outputId":"a980f6eb-8fff-492b-8f72-293f7642452c"},"outputs":[],"source":["displacy.render(nlp_model('The girl saw a man with a telescope.'),jupyter=True,style='dep')"]},{"cell_type":"markdown","metadata":{"id":"_fIZq6zIhPbk"},"source":["The second sentence is ambiguous: The girl may have made use of her telescope or the man may have been using the girl's telescope...\n","- Language is full of such ambiguities which we as humans naturally deal with using our prior knowledge and abilty to construct mental models of the situations described.\n","- This process is not without its biases:\n","  - *The doctor went over to talk to the nurse. She told him that she had just given the patient 5mg of Vicodin and the child had started convulsing. He listened attentively as she explained what had happened. The doctor was worried that the patient should not be given any more painkillers. The nurse told the doctor not to worry, that the patient was in good hands, and that he would let her know immediately if the child's condition changed.*\n","  - What gender are the doctor and the nurse?"]},{"cell_type":"markdown","metadata":{"id":"4uE1efbqpdl3"},"source":["## Extracting Entities\n","\n","A more important output than the depency parse, from a text mining perspective, is the list of named-entities present in the text\n","- **named entities** are objects in the real world, e.g. persons, products, organizations, locations, etc. \n","  - see https://en.wikipedia.org/wiki/Named_entity\n","- if spacy has found any named entities while parsing the text, we can access them as follows:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":730,"status":"ok","timestamp":1680621375867,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"irYwH5WVpdl3","outputId":"aae8331c-40b5-4fa6-ec0b-9bdf4924c025"},"outputs":[],"source":["parsed_text.ents"]},{"cell_type":"markdown","metadata":{"id":"rv6krbXmpdl3"},"source":["Note that the entities are not single word tokens but short sequences of words: 'Stage 3' and 'Daniel Andrews'.\n","\n","Not only does spacy extract the entities, but also categorises them based on their type:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1680621377272,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"EXA2FRzXpdl4","outputId":"11309cbc-bf93-4f4b-b1be-a355e020f3fc"},"outputs":[],"source":["print([(ent.text, ent.label_) for ent in parsed_text.ents])"]},{"cell_type":"markdown","metadata":{"id":"fyp09Uelpdl4"},"source":["The city and country locations have been labeled 'GPE' for 'geopolitical entity', while the Premier of Victoria has been correctly identified as a person. \n","- Here is the list of all entity types that spaCy looks for: https://spacy.io/api/annotation#section-named-entities\n","\n","Internally, the output of the Named Entity Recogniser is a sequence annotated with entities using inside-outside-beginning encoding: \n","- see https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)\n","- We can print out this labeling as follows:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":538,"status":"ok","timestamp":1680621381215,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"-E1H-RM6pdl4","outputId":"ee11d920-22b0-4fa5-aefb-b83a8f5b0f96"},"outputs":[],"source":["[(X, X.ent_iob_, X.ent_type_) for X in parsed_text]"]},{"cell_type":"markdown","metadata":{"id":"10tU8n44pdl4"},"source":["The above format is a bit hard to read though, so spaCy also provides a far more natural visualisation of the tags:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"elapsed":71,"status":"ok","timestamp":1680621382227,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"9PmUl2y5pdl4","outputId":"cebdb375-c3f8-435d-8ae2-c4e6b2b3c739"},"outputs":[],"source":["displacy.render(parsed_text, jupyter=True, style='ent')"]},{"cell_type":"markdown","metadata":{"id":"VS1PK7ifpdl5"},"source":["## Extracting entities from a web document\n","\n","Now that we know how to perform entity recognition on text, let's apply it to a full document"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1476,"status":"ok","timestamp":1680621395467,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"8pY-nN0Zpdl5"},"outputs":[],"source":["url = 'https://www.bbc.com/news/world-latin-america-53319517'\n","#url = 'https://en.wikipedia.org/wiki/Apple_(disambiguation)'\n","\n","import requests\n","html_doc = requests.get(url).text\n","\n","from bs4 import BeautifulSoup\n","parsed_doc = BeautifulSoup(html_doc, 'lxml')"]},{"cell_type":"markdown","metadata":{"id":"LRe5AUvCpdl5"},"source":["Now lets extract the title and paragraph text:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":312,"status":"ok","timestamp":1680621402868,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"e5YGoQISpdl5","outputId":"1bc44528-992f-4106-97f8-dc5d61b97672"},"outputs":[],"source":["title = parsed_doc.find('title').text\n","paragraphs = [p.text for p in parsed_doc.find_all('p')]\n","\n","# Combine the title and paragraphs into a single text:\n","article_text = title + '\\n\\n' + '\\n'.join(paragraphs)\n","print(article_text)\n","\n","#article_text = parsed_doc.get_text()\n","#print(article_text)"]},{"cell_type":"markdown","metadata":{"id":"y_dqist0pdl5"},"source":["---\n","\n","Parse the article to identify the entities and display them: "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":702,"status":"ok","timestamp":1680621409585,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"RMTsfAhYpdl6","outputId":"1cfe43b1-bde3-4de8-b057-2cf03fd27a97"},"outputs":[],"source":["parsed_article = nlp_model(article_text)\n","displacy.render(parsed_article,jupyter=True,style='ent')"]},{"cell_type":"markdown","metadata":{"id":"6I8_zJQrpdl6"},"source":["---\n","\n","What do you think? Did it work?\n","\n","Let's have a bit of a better look at the entities found\n","- List all the distinct entities found in the article, sorted alphabetically:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1680621411094,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"SakcaXuypdl6","outputId":"d08a970e-a172-4041-ea4a-8889c58bbeae"},"outputs":[],"source":["sorted(set(x.text for x in parsed_article.ents))"]},{"cell_type":"markdown","metadata":{"id":"jyGeLXs8pdl6"},"source":["We can count the number of times each **entity type** occurs:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1680621411095,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"mcmsbiUkpdl6","outputId":"2fb972cb-cc1c-4a3d-e417-a072b44c80b1"},"outputs":[],"source":["from collections import Counter\n","\n","labels = [x.label_ for x in parsed_article.ents]\n","Counter(labels)"]},{"cell_type":"markdown","metadata":{"id":"Tb3g9y5Kpdl6"},"source":["We can also count the number of times each **entity name** occurs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1680621412078,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"JPdOsoiApdl6","outputId":"e923dee0-6d3a-4d46-aff5-fe854cfa8669"},"outputs":[],"source":["items = [x.text for x in parsed_article.ents]\n","Counter(items).most_common()"]},{"cell_type":"markdown","metadata":{"id":"vEV2BJCTpdl7"},"source":["Note that some of the phrases refer to the same entity, e.g. 'Mr Bolsonaro' and just 'Bolsonaro'.\n","- Entity Linking and Reference Resolution are the NLP problems that deal with resolving the different references to the same entity in the text.\n","\n","If we were only interested in what was being said about Bolsonaro, \n","- we could select only sentences refering to him:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1169,"status":"ok","timestamp":1680621423349,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"oNXjt46Jpdl7","outputId":"1804cc23-9818-4836-91eb-b919972d83de"},"outputs":[],"source":["sentences_containing_Bolsonaro = [x for x in parsed_article.sents if 'Bolsonaro' in x.text]\n","displacy.render(sentences_containing_Bolsonaro,jupyter=True,style='ent')"]},{"cell_type":"markdown","metadata":{"id":"XkJvASO9pdl7"},"source":["## Named Entity Extraction in Italian\n","\n","But wait, SpaCy can speak Italian too!\n","- Let's make use of the pretrained italian model that we downloaded earlier: https://spacy.io/models/it\n","- to recognise entities in an article from 'Il Corriere'\n","\n","First download the article:"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":691,"status":"ok","timestamp":1680621427606,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"BCTkJTsopdl7"},"outputs":[],"source":["url = 'https://www.ansa.it/sito/notizie/mondo/2020/07/07/bolsonaro-ha-i-sintomi-del-coronavirus_40d26967-e377-4455-9b42-83c2756cf5f1.html'\n","html_doc = requests.get(url).text\n","parsed_doc = BeautifulSoup(html_doc, 'lxml')"]},{"cell_type":"markdown","metadata":{"id":"rrnqQcMOpdl7"},"source":["Now let's extract the title and paragraph text:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":299,"status":"ok","timestamp":1680621430116,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"OIyIysghpdl7","outputId":"51c46dc1-9599-4d4e-bc53-848538c32669"},"outputs":[],"source":["title = parsed_doc.find('title').text\n","paragraphs = [p.text for p in parsed_doc.find_all('p')]\n","\n","# Combine the title and paragraphs into a single text:\n","article_text = title + '\\n\\n' + '\\n'.join(paragraphs)\n","print(article_text)"]},{"cell_type":"markdown","metadata":{"id":"eluDQCqxpdl7"},"source":["---\n","\n","Now we'll parse the text of the article with an Italian NLP engine to extract Named Entities.\n","- First load the italian model 'it_core_news_sm' that we downloaded earlier"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":982,"status":"ok","timestamp":1680621438007,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"Qj0IIHlVpdl7"},"outputs":[],"source":["import it_core_news_sm\n","nlp_it = it_core_news_sm.load()"]},{"cell_type":"markdown","metadata":{"id":"BcWwDGlypdl8"},"source":["Parse article and extract the entities:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":457,"status":"ok","timestamp":1680621440848,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"1X-Kuw6lpdl8","outputId":"38d53435-2bd6-43e5-c976-5b088fe40414"},"outputs":[],"source":["parsed_article = nlp_it(article_text)\n","displacy.render(parsed_article, jupyter=True, style='ent')"]},{"cell_type":"markdown","metadata":{"id":"08h69wcxpdl8"},"source":["That looks not great. \n","- Here are the entities found in the news article: "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1680621442650,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"UKefi_fspdl8","outputId":"bb3d9dc4-44bc-4ea9-f42d-4af710591444"},"outputs":[],"source":["sorted(set(x.text for x in parsed_article.ents))"]},{"cell_type":"markdown","metadata":{"id":"8GNZaLqN4Dx-"},"source":["Alterantively you can use Stanza (https://stanfordnlp.github.io/stanza/). It's very similar to spaCy:\n","- Python package\n","- Supports multiple languages\n","- Uses deep neural network modules\n","\n","Let's start installing the library"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9622,"status":"ok","timestamp":1680621556101,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"a6JmKZ3xLPwI","outputId":"5a224fbb-80fd-483c-89f6-811bf98b8f03"},"outputs":[],"source":["import locale\n","locale.getpreferredencoding = lambda: \"UTF-8\"\n","!pip install stanza"]},{"cell_type":"markdown","metadata":{"id":"NazOsrqKLgtW"},"source":["Now we can import Stanza and create a pipeline for Italian"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":526,"referenced_widgets":["3a6cda4550814d688c1f933f586844f8","c1f5a07455c7439e8fa5e21e398fa2b0","1cff1ebe875e4d6c9aee998441263e3f","e3329f86180a4f878dbc8863e059f2a1","72901170aee540128f442465cced481d","70b3d8de3bde4f5a8b331fbe11737a02","d9fe139593184666858f38d24c07f93b","894eed98e66145f6b2119a5dabc28aed","2ea90a0d682f48fc9c19e121d052b2c3","1f3857e7f59e4c07a581bced61f6e91b","9fa5e3d27b0e4120a3e4ab54b4132a3e","9e607eaa7047442aae90cfae83039438","9b82d939d6634a07aca08d476d2b5326","9dc5e6a9f35a46adba95ab3a22e65c1f","46649e92e7194805962ec36c97057c2a","c9bde1772e004b4186caa582e33463d0","e57c7471dc914699a0329e36c2d46bce","92d6a2c55a404f7680c8596579d9c1dc","3d63c623e998446483d44389f685abe2","d1aa62b7121b4db28380780b5abc7bfe","c2f6bb3a7f904b2ab12c12168d67dd6e","8c5451b5e1ad475f99ede13833a328f7","ca95de1a2337440a82a62364d29648f3","e2dd95f03f6149e38457c66a0258d533","0c8c937870834179abeb572df4d0d552","f5e7e60c8ddb4c42918459b494543e35","ea1d40350be84b848d3ba02cf9abfe0e","a84b76d7ccbe4172bc191d3bb23bf615","45a25e6c154b468b9d7d6fa785cbaae2","8899fb38e0d14cd29281285e3a42b51b","bcd8f46d9f414f429f81d1df02838d51","3539ff61c6e04ab09eeec4964ce1c9db","34835e0f6b804e8c92ac149286b94d7f","51e99a99171b4e2db399fd618bf8c0c9","942674ea474641cd89d3f0fec140024b","5bad16cc99114049a8cc859a338fd6c1","fe5b7dac4b714bb2b771b0ff0a3e5ddc","6cf1079ca2484cab8bff9c6f79227477","f0b954a656e0426f82fa67183b1ea28c","cc60fc78d637456188ee49c4291eaa90","e0fe780f411f432eae0dbf82e4717e2a","859dfd0aa4574ea4be667133817677f6","2a5a57a23d8f4a9ab96db2abb52b486f","c6f28ff3a8244a729b3fe9901c07559b","808fb5dffc824cd69c2380e9be854778","7b402deff2894db6b632e2ac9ee647cd","194b8a513203433b8e0701150f36a41c","e72c523335444386b35c398225e7b770","482a1ffafc894b399dee4e30a68c0cd0","dfd655af8757410d922efef737f11c28","9ac782a738f242aaaf2caa1b98553552","5446764ef1bb4dec8356ccba6398a582","72a207a566aa40e492ae78bbcb19c469","aa4729f8e6fd4552ad0d30fab533fd4c","0cba6e75539b4d19b8d570a404497b51","50848de518c14419a350027e54032cdf","d3a38c4c27284966abdb4994d20f5363","afb80bae23454de595e08d937eda4a6b","ef5f36be5fbc4b9182137df1ba12ce3f","a8ed2c31164447159d3ac543f08a91ee","0974d75f27f54ec6a6b2178bf1b9744d","61881593408345b298c62a0a5634b69f","d7cae6a5940744e3af1f3f13b44ff41c","7729d46c99aa4037998116e202acbb72","d4513a2cde814f5d874800f5e222b4ab","726cf2f1a4b340af9be3d6549825eb3b","d93024b54175448983d17ffb9cd50f6a","33f31ff150b0454c87265dc1b0ee9a66","f66d7bb7a7f34ee99aac3a6862b4b00a","14444e6b397d4fe484074bff601312c5","1fd6ab8bdf494cea8a98a1f25b8175cf","727cf550c6304701a87e692f987d3bb2","d19c8ea288714972b80177dbb411582f","017463dc321c43b89278a5cf4888444f","42787d1154914368b031860461fd09c4","a178b1869b774ba687649b344e804478","0a2b7b8947b3496da3c4ce8377573368"]},"executionInfo":{"elapsed":8466,"status":"ok","timestamp":1680621567970,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"X2vbIhiQLfhH","outputId":"f28f40bb-dabd-40fd-d366-2fa715f5399e"},"outputs":[],"source":["import stanza\n","\n","stanza_nlp_model = stanza.Pipeline(lang='it', processors='tokenize,ner')"]},{"cell_type":"markdown","metadata":{"id":"aN8vExE_MWGK"},"source":["As before we need to parse the document"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2055,"status":"ok","timestamp":1680621574840,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"OHqxZTBALfm7"},"outputs":[],"source":["stanza_parsed_article = stanza_nlp_model(article_text)"]},{"cell_type":"markdown","metadata":{"id":"XHx67HKdMtNi"},"source":["Given a document, Stanza breaks it into sentences and then tokens.\n","For each token adds the tags using the sleected processors (here we are using only the NER processors).\n","\n","Let's give a look at the identified entities:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":301,"status":"ok","timestamp":1680621579200,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"Cw98dV1yLfsu","outputId":"05d50243-c3f2-4ceb-e54e-357f175af600"},"outputs":[],"source":["for sentence in stanza_parsed_article.sentences:\n","    for entity in sentence.ents:  # Hello, Treebeard!\n","        print(f\"{entity.text}: {entity.type}\")"]},{"cell_type":"markdown","metadata":{"id":"9LDtG1YcN__S"},"source":["That's a bit better than before, don't you think?"]},{"cell_type":"markdown","metadata":{"id":"pzFM8cAUpdl8"},"source":["## Fine-tuning your own NER Model\n","\n","What if you want to update the Named Entity Extraction model yourself in order to customize it to your set of entities? We'll have a look at that now based on:\n","- this instructions page: https://spacy.io/usage/training#ner\n","- and this blog post: https://towardsdatascience.com/custom-named-entity-recognition-using-spacy-7140ebbb3718\n","\n","In order to fine-tune the model, we need to prepare data in the following format: \n","- a piece of text, \n","- plus a list of entity types that occur it along with their positions."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":346,"status":"ok","timestamp":1680621627880,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"d8aaj2uepdl8","outputId":"68979fec-e4da-45d3-99ac-1eb1ad9cec92"},"outputs":[],"source":["my_data = [\n","    (\"Have you heard of an associate professor from the Politecnico di Milano called Mark Carman?\", {\"entities\": [(50, 71, \"ORG\"),(79, 90, \"PERSON\")]}),\n","    (\"No, I haven't, but I don't know many people at the Politecnico. What does he work on?\", {\"entities\": [(51, 62, \"ORG\")]}),\n","    (\"Mainly machine learning and text mining. I met him a couple of years ago at SIGIR in Tokyo.\", {\"entities\": [(76, 81, \"EVENT\"),(85, 90, \"GPE\")]}),\n","]\n","my_data"]},{"cell_type":"markdown","metadata":{"id":"bnVIriSEpdl9"},"source":["Where would this data come from? \n","- either created manually, perhaps by searching for known individuals in a text collection,\n","- or by using an annotation tool such as https://doccano.herokuapp.com/, see for example: https://medium.com/@justindavies/training-spacy-ner-models-with-doccano-8d8203e29bfa\n"]},{"cell_type":"markdown","metadata":{"id":"1s9T3Whe5lZJ"},"source":["The following code comes from here: https://github.com/explosion/spaCy/blob/master/examples/training/train_ner.py\n","- The only change made was to remove the training data\n","\n","Before starting we need to install the plac package"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6976,"status":"ok","timestamp":1680621641710,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"P057B5jUQjqM","outputId":"7543b693-0190-4377-e39c-00b5e8dcc0ac"},"outputs":[],"source":["!pip install plac"]},{"cell_type":"markdown","metadata":{"id":"2-oMt4jRQj2k"},"source":["Now we define function with the training loop:"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1680622120493,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"jVjhWJ1Zpdl9"},"outputs":[],"source":["from __future__ import unicode_literals, print_function\n","\n","import plac\n","import random\n","import warnings\n","from pathlib import Path\n","import spacy\n","from spacy.util import minibatch, compounding\n","from spacy.training.example import Example\n","\n","\n","@plac.annotations(\n","    model=(\"Model name. Defaults to blank 'en' model.\", \"option\", \"m\", str),\n","    output_dir=(\"Optional output directory\", \"option\", \"o\", Path),\n","    n_iter=(\"Number of training iterations\", \"option\", \"n\", int),\n",")\n","def main(model=None, output_dir=None, n_iter=100):\n","    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n","    if model is not None:\n","        nlp = spacy.load(model)  # load existing spaCy model\n","        print(\"Loaded model '%s'\" % model)\n","    else:\n","        nlp = spacy.blank(\"en\")  # create blank Language class\n","        print(\"Created blank 'en' model\")\n","\n","    # create the built-in pipeline components and add them to the pipeline\n","    # nlp.create_pipe works for built-ins that are registered with spaCy\n","    if \"ner\" not in nlp.pipe_names:\n","        ner = nlp.create_pipe(\"ner\")\n","        nlp.add_pipe(ner, last=True)\n","    # otherwise, get it so we can add labels\n","    else:\n","        ner = nlp.get_pipe(\"ner\")\n","\n","    # add labels\n","    for _, annotations in TRAIN_DATA:\n","        for ent in annotations.get(\"entities\"):\n","            ner.add_label(ent[2])\n","\n","    # get names of other pipes to disable them during training\n","    pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n","    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n","    # only train NER\n","    with nlp.disable_pipes(*other_pipes), warnings.catch_warnings():\n","        # show warnings for misaligned entity spans once\n","        warnings.filterwarnings(\"once\", category=UserWarning, module='spacy')\n","\n","        # reset and initialize the weights randomly – but only if we're\n","        # training a new model\n","        if model is None:\n","            nlp.begin_training()\n","        for itn in range(n_iter):\n","            random.shuffle(TRAIN_DATA)\n","            losses = {}\n","            # batch up the examples using spaCy's minibatch\n","            batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n","            for batch in batches:\n","                # Create example\n","                examples = [\n","                    Example.from_dict(nlp.make_doc(text), annotation) \n","                    for text, annotation in batch\n","                ]\n","                # Update the model\n","                nlp.update(\n","                    examples,   # batch of texts and annotations\n","                    drop=0.5,  # dropout - make it harder to memorise data\n","                    losses=losses,\n","                )\n","            print(\"Losses\", losses)\n","\n","    # test the trained model\n","    for text, _ in TRAIN_DATA:\n","        doc = nlp(text)\n","        print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n","        print(\"Tokens\", [(t.text, t.ent_type_, t.ent_iob) for t in doc])\n","\n","    # save model to output directory\n","    if output_dir is not None:\n","        output_dir = Path(output_dir)\n","        if not output_dir.exists():\n","            output_dir.mkdir()\n","        nlp.to_disk(output_dir)\n","        print(\"Saved model to\", output_dir)\n","\n","        # test the saved model\n","        print(\"Loading from\", output_dir)\n","        nlp2 = spacy.load(output_dir)\n","        for text, _ in TRAIN_DATA:\n","            doc = nlp2(text)\n","            print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n","            print(\"Tokens\", [(t.text, t.ent_type_, t.ent_iob) for t in doc])"]},{"cell_type":"markdown","metadata":{"id":"O1pM_VOIpdl9"},"source":["Once the above model has been defined, we can update and save the model\n","- Note that this code doesn't currently run in Google colab. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1993,"status":"ok","timestamp":1680622125109,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"o1cpkZGWpdl9","outputId":"204c4039-4318-4b0d-91cf-0dba03dbe058"},"outputs":[],"source":["TRAIN_DATA=my_data  # The method expects the training data to have this name\n","main(model='en_core_web_sm',output_dir='spacy_model',n_iter=5)"]},{"cell_type":"markdown","metadata":{"id":"MlicBTgepdl-"},"source":["## Entity Linking in spaCy\n","\n","We don't want to just find entity mentions in a document but link them to a known entity in a knowledge base. \n","- The task of linking the entity mentions to the corresponding entity in the knowledge base is called 'Entity Linking'.\n","- I don't have time here, but watch this video to learn more: \n","https://spacy.io/universe/project/video-spacy-irl-entity-linking"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_BKB-yMKpdl-"},"outputs":[],"source":["# TODO"]},{"cell_type":"markdown","metadata":{"id":"a7Yi8kv_SPL8"},"source":["## Sequence labelling with embeddings and a Recurrent Neural Network\n","\n","In this section of the notebook I will run through an example of using LSTM (Long Short-term Memory) network for text sequence labelling.\n","We can train our own model for POS-tagging or NER.\n","Moreover, we can use pre-trained embedding models to encode the input text.\n","\n","- We are going to use PyTorch (https://pytorch.org) to build and train our model. Pytorch is a state-of-the-art framework for deep leaning."]},{"cell_type":"markdown","metadata":{"id":"5TOBlQWzTeZv"},"source":["### Data preparation\n","\n","As usula we start from data preparation. \n","We can use the [WikiNER](https://www.sciencedirect.com/science/article/pii/S0004370212000276) corpus, which provides corpora for POS-tagging and NER in multiple languages.\n","Today we are going to focus on NER.\n","\n","You can find a copy the English split in the `doc/` directory. \n","All the parts of the corpus are avaialble here: https://figshare.com/articles/dataset/Learning_multilingual_named_entity_recognition_from_Wikipedia/5462500\n","\n","Let's start by loading the file in memory and reading it line by line. Each line corresponds to a sentence."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2016,"status":"ok","timestamp":1680614391711,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"RwzHtg6oTn8h","outputId":"431f471c-b630-423d-fe7f-b49c7af312e5"},"outputs":[],"source":["with open('docs/aijwikinerenwp3') as f:\n","    wiki_ner_data = f.read().strip().split('\\n')\n","wiki_ner_data[:10]"]},{"cell_type":"markdown","metadata":{"id":"4pKqvTd1WYuZ"},"source":["Now we can parse the data. \n","Tokens are separated by spaces and for each token we have the associated POS tag and the NER tag written as: `<token>|<POS tag>|<NER tag>`.\n","\n","Here NER tags are written using a system called BIO-tagging.\n","The 'B' stands for \"begin\" and introduces (starts) a new named entity, the tags are written as \"B-PER\" to indicate a person or \"B-LOC\" to indicate a location and so on. \n","The 'I' stands for \"inside\" and continues a started named entity, the tags are written as \"I-PER\" to indicate a person or \"I-LOC\" to indicate a location and so on. \n","The 'O' stands for outside, it means that the token is outside any named entity. \n","There are other tagging systems.  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3542,"status":"ok","timestamp":1680614400149,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"kGHVXha_ToEl","outputId":"0e2e43c7-90a4-4e8d-e712-a72b7fbbe7d2"},"outputs":[],"source":["keys = ['text', 'pos_tag', 'ner_tag']\n","wiki_ner_data = [[dict(zip(keys, token.split('|'))) for token in sentence.split()] for sentence in wiki_ner_data]\n","\n","wiki_ner_data[0]"]},{"cell_type":"markdown","metadata":{"id":"5jFlDXEXYHYe"},"source":["Now all the labels are properly organised"]},{"cell_type":"markdown","metadata":{"id":"SZ1C75ufYHm3"},"source":["At this point we need a system ti encode and decode the labels into categorical entities. \n","We can use the label encoder from Scikit-Learn for that (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4568,"status":"ok","timestamp":1680614411405,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"gtsVjf7pToKs"},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","pos_le = LabelEncoder().fit([token['pos_tag'] for sentence in wiki_ner_data for token in sentence])\n","ner_le = LabelEncoder().fit([token['ner_tag'] for sentence in wiki_ner_data for token in sentence])"]},{"cell_type":"markdown","metadata":{"id":"MJrbdDZ2Z_-K"},"source":["Now we have a module mapping from tags to IDs and vice-versa"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":316,"status":"ok","timestamp":1680614413953,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"UoHsG_1XToPI","outputId":"3a89e0e3-1fcd-4334-e027-a34631654d10"},"outputs":[],"source":["ner_tag = ['I-PER']\n","# ner_tag = ['I-LOC']\n","# ner_tag = ['B-PER']\n","# ner_tag = ['O']\n","\n","ner_le.transform(ner_tag)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":491,"status":"ok","timestamp":1680614419702,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"0BFX3l8Jau4S","outputId":"9776c6d4-47dc-458c-e937-6589053a182c"},"outputs":[],"source":["ner_tag_id = [0]\n","\n","ner_le.inverse_transform(ner_tag_id)"]},{"cell_type":"markdown","metadata":{"id":"vsL58BEua48X"},"source":["How many NER tags do we have? "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1680614421871,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"MluEFeCFbOYl","outputId":"83c032e8-ed31-45cf-a7ed-d2bdf755f6e9"},"outputs":[],"source":["len(ner_le.classes_)"]},{"cell_type":"markdown","metadata":{"id":"iVGvRsmTatEq"},"source":["Which are those tags?"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":916,"status":"ok","timestamp":1680614426734,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"fIZUZQJabHT-","outputId":"bbff6636-f8b7-4fbf-f79e-12c1181df778"},"outputs":[],"source":["ner_le.classes_"]},{"cell_type":"markdown","metadata":{"id":"KbAeRowAatSg"},"source":["Collect the same info for POS tags"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1680614428918,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"hfkNqH4ObDcM"},"outputs":[],"source":["# TODO"]},{"cell_type":"markdown","metadata":{"id":"jQRJ2JTgb6tW"},"source":["Finally we can do our train-validation-test split"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1458,"status":"ok","timestamp":1680614431109,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"qgQjMJIQb_Ju"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","tmp_data, test_data = train_test_split(wiki_ner_data)\n","train_data, valid_data = train_test_split(wiki_ner_data)"]},{"cell_type":"markdown","metadata":{"id":"qOmLfsEhTerk"},"source":["### Defining and training the RNN model for NER"]},{"cell_type":"markdown","metadata":{"id":"BbYECVf6cygn"},"source":["We start by installing PyTorch and importing the required modules"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4267,"status":"ok","timestamp":1680614438959,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"laZ0X6Q1c7o8","outputId":"6d8c6651-d24e-4fd0-b090-7e50ca8be733"},"outputs":[],"source":["!pip install torch"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":633,"status":"ok","timestamp":1680617322365,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"jiZ9aqFdcy5p"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"markdown","metadata":{"id":"zOnFKlCNfuS2"},"source":["The we load the Word Embedding model we want to use. We can re-use the 50 dimensional GloVe emebddings from last time"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15572,"status":"ok","timestamp":1680617338684,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"V_1tfiIYfuhs"},"outputs":[],"source":["import gensim.downloader as api\n","\n","we_model = api.load(\"glove-wiki-gigaword-50\")"]},{"cell_type":"markdown","metadata":{"id":"9YX30FkkckpT"},"source":["Before creating the LSTM we decide where to train our model, either cpu or gpu, depending on which is avaialble."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":77,"status":"ok","timestamp":1680617338684,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"e6v_WgFyclBl","outputId":"ad7e1d10-801b-499f-8e33-e1576404e246"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"7WAxAGcPcUeH"},"source":["Now we can create our RNN module.\n","Here are the available modules for PyTorch: https://pytorch.org/docs/stable/nn.html#recurrent-layers\n","\n","We define a custom LSTM using PyTorch API.\n","In our model we stack one or more LSTM layers (we can make it variable) and we put a linear layer (a.k.a. dense layer or fully connected layer on top of it).\n","\n","When you define a neural network in PyTorch you need it to extend the `torch.nn.Module` class and implement the forward method (the one that computes the output)."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1534,"status":"ok","timestamp":1680620204968,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"hlNzxkt3kFdJ"},"outputs":[],"source":["class CustomLSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size, n_lstm=1):\n","        super().__init__()\n","        # List of LSTM layers\n","        self.lstm = nn.ModuleList([\n","            nn.LSTM(\n","                input_size=input_size if i == 0 else hidden_size, \n","                hidden_size=hidden_size, \n","                batch_first=True,\n","                dropout=0.2\n","            )\n","            for i in range(n_lstm)\n","        ])\n","        # Lat linear projection\n","        self.cls_head = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x):\n","        # Run though all the LSTM layers\n","        for lstm_layer in self.lstm:\n","            # Compute new hidden representation\n","            x, _ = lstm_layer(x)\n","        # Apply last lineat projection\n","        y = self.cls_head(x)\n","\n","        return y"]},{"cell_type":"markdown","metadata":{"id":"DGLK7ZcNkFzA"},"source":["Let's create an instance of our LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1680620204969,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"Q16YNMfycU5e","outputId":"79115e4e-9f91-4af6-d11d-88988a4c19cf"},"outputs":[],"source":["lstm = CustomLSTM(50, 50, len(ner_le.classes_), n_lstm=3)\n","lstm"]},{"cell_type":"markdown","metadata":{"id":"g0IKmAl7fXxl"},"source":["Now we can move the LSTM to the target device"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1680620205516,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"B8Oz89mtfYPJ"},"outputs":[],"source":["lstm = lstm.to(device)"]},{"cell_type":"markdown","metadata":{"id":"-HKv1-rrcVRs"},"source":["Once we have the model we need to create an optimizer that will take care of updating the weights. Here are the available optimizers: https://pytorch.org/docs/stable/optim.html.\n","I'm going to use RMSProp.\n","\n","The optimizer needs to receive the parameters of the neural network and the selected learning rate"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1680620206632,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"9LyIZYvUcVjA"},"outputs":[],"source":["lr = 0.0005\n","optimizer = torch.optim.RMSprop(params=lstm.parameters(), lr=lr)"]},{"cell_type":"markdown","metadata":{"id":"nNC5JzcpcVxx"},"source":["Now we need to prepare our data. \n","Before doing so we prepare a function that maps a mini-batch of samples (i.e., a subset of the lists of dictionaries we prepared) to input tensors to use with our model. The function willl take care of:\n","- Mapping all words to their embeddings with size $d$\n","- Collect the emebddings of the same sentence into a matrix with shape $(n_\\textit{words in sentence}, d)$\n","- Collect the different matrices of the same batch into a single tensor with shape $(n_\\textit{batch elements}, n_\\textit{words in longest sentence}, d)$ (this will be input).\n","- Mapping all the labels to their IDs \n","- Collecting all the IDs of the same sentence into a vector with size $n_\\textit{words in sentence}$ \n","- Collecting all the different vectors into a matrix with shape $(n_\\textit{batch elements}, n_\\textit{words in longest sentence})$ (this will be target output).\n","\n","Note that different sentences have different lengths, to cope with this issue we apply a process called padding: we are going to add to the input tensor and the target output matrix  dummy values to have all the same \"sentence length\"."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1680620206633,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"XiCDLg0qcWCR"},"outputs":[],"source":["import numpy as np\n","\n","def collate(mini_batch):\n","    # Get the length of the longest sentence\n","    longest_len = max(len(sample) for sample in mini_batch)\n","    # Create an input tensor with all zero values\n","    input_embeds = np.zeros((len(mini_batch), longest_len, 50))\n","    # Create a target output matrix with all -100 (PyTorch ignores this value by default)\n","    output_lbl = np.full((len(mini_batch), longest_len), -100)\n","    # Fill the tensor and the matrix\n","    for i, sample in enumerate(mini_batch):\n","        for j, token in enumerate(sample):\n","            # Manage missing tokens in vocabulary\n","            if token['text'].lower() in we_model:\n","                input_embeds[i,j] = we_model[token['text'].lower()]\n","            output_lbl[i,j] = ner_le.transform([token['ner_tag']])\n","    # Convert to PyTorch tensor\n","    input_embeds = torch.tensor(input_embeds, dtype=torch.float)\n","    output_lbl = torch.tensor(output_lbl)\n","\n","    return input_embeds, output_lbl"]},{"cell_type":"markdown","metadata":{"id":"xzEg6gg9k62U"},"source":["How does an encoded batch looks like? Let's enode the first three sentences"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1680620207196,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"ZgvoOTG4k7Lx","outputId":"5003734f-c98c-47e5-9b89-52da882feadd"},"outputs":[],"source":["train_data[:3]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1680620209795,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"ZFQlJoPUlyIH","outputId":"2cda0665-0e50-4dec-a35b-04464dcad982"},"outputs":[],"source":["embeds, lbl = collate(train_data[:3])\n","\n","print(f\"The shape of the input is: {embeds.size()}\")\n","print(f\"The shape of the output is: {lbl.size()}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":604,"status":"ok","timestamp":1680620211447,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"zGD62Kj4mNsA","outputId":"2c38a6df-8c0d-4f5b-9219-eb4569ea382d"},"outputs":[],"source":["embeds"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1680620211447,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"E3FAiBTJmN16","outputId":"b33e2b62-0597-4948-9b39-637a32b25da5"},"outputs":[],"source":["lbl"]},{"cell_type":"markdown","metadata":{"id":"i3TpDkJ8cWUR"},"source":["Now we can finally wrap a DataLoader around our samples. PyTorch data loaders take care of generating batches on a given data set. We just need to set the batch size."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":948,"status":"ok","timestamp":1680620217411,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"moRFz8fycWhv"},"outputs":[],"source":["batch_size = 32\n","\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, collate_fn=collate, shuffle=True)\n","valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, collate_fn=collate)\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, collate_fn=collate)"]},{"cell_type":"markdown","metadata":{"id":"D-SKOksvmxuq"},"source":["We can train the lst iterating over the data set for a given number of epochs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":572735,"status":"ok","timestamp":1680620792473,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"92NG8pwTmyIp","outputId":"6fdc35dc-821b-42ba-f8e7-a8be638de0bd"},"outputs":[],"source":["# Import nice loading bar using tqdm\n","from tqdm import tqdm\n","\n","# Set model in training mode\n","lstm.train()\n","\n","# Accumulator of loss\n","history = [] \n","\n","n_epochs = 3\n","\n","# Iterate over epochs\n","for i in range(n_epochs):\n","    print(f\"Starting epoch {i + 1}/{n_epochs}\")\n","    # Iterate over training batches\n","    for embeds, lbl in tqdm(train_loader):\n","        # Zero your gradients for every batch!\n","        optimizer.zero_grad()\n","        # Move input and output to target device\n","        embeds = embeds.to(device)\n","        lbl = lbl.to(device)\n","        # Compute logits (i.e., softmax values before exponential normalisation)\n","        logits = lstm(embeds)\n","        # Flatten logits to a shape (batch_size * max_sentence_len, n_classes)\n","        logits = logits.reshape(-1, len(ner_le.classes_))\n","        # Flatten targets to a shape (batch_size * max_sentence_len)\n","        lbl = lbl.reshape(-1)\n","        # Compute loss\n","        loss = F.cross_entropy(logits, lbl)\n","        # Compute gradients\n","        loss.backward()\n","        # Update weights\n","        optimizer.step()\n","        # Save loss\n","        history.append(loss.detach())\n","\n","history = [loss.cpu().item() for loss in history]"]},{"cell_type":"markdown","metadata":{"id":"m6RIgReTdAn4"},"source":["Now we can plot the evolution of the loss at each update"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":486},"executionInfo":{"elapsed":464,"status":"ok","timestamp":1680620797594,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"ZzgJs7wac_fL","outputId":"bf79723e-7cca-4f1b-b066-243f08eb67af"},"outputs":[],"source":["from matplotlib import pyplot as plt\n","%matplotlib inline\n","\n","plt.figure()\n","plt.plot(range(len(history)), history)\n","plt.xlabel('Update step')\n","plt.ylabel('Loss')"]},{"cell_type":"markdown","metadata":{"id":"jf28zwGSmyXE"},"source":["We can also test out model using the dedicated split. We iterate over the mini batches, colelct the prediction as the value with the highest logit value and we store these values until we go through the entire data set. Then we compute the classification report"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":76737,"status":"ok","timestamp":1680620894832,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"v6_NYT35myps","outputId":"4e729dc8-71ed-4d46-c34a-f18ebcf4f60c"},"outputs":[],"source":["from sklearn.metrics import classification_report\n","\n","# Set model in evaluation mode\n","lstm.eval()\n","\n","# Accumulators for target labels and predictions\n","y_true = []\n","y_pred = []\n","\n","# Disable gradients\n","with torch.no_grad():\n","    # Iterate over validation batches\n","    for embeds, lbl in tqdm(valid_loader):\n","        # Move input and output to target device\n","        embeds = embeds.to(device)\n","        # Compute logits (i.e., softmax values before exponential normalisation)\n","        logits = lstm(embeds)\n","        # Get predictions as the index corresponding to the highest logit score\n","        pred_lbl = torch.argmax(logits, dim=-1)\n","        # Append predicted labels\n","        y_pred.append(pred_lbl.reshape(-1).cpu().numpy())  \n","        # Append target labels\n","        y_true.append(lbl.reshape(-1).numpy())\n","\n","# Concatenate all the vectors of target labels and predicted labels\n","y_true = np.concatenate(y_true)\n","y_pred = np.concatenate(y_pred)\n","# Remove elements to ignore (the -100 labels)\n","mask = y_true == -100\n","y_true = y_true[~mask]\n","y_pred = y_pred[~mask]\n","\n","# Finally compute classification report\n","print(classification_report(y_true, y_pred, target_names=ner_le.classes_))"]},{"cell_type":"markdown","metadata":{"id":"ulRr7wzmdlMo"},"source":["What's the issue here? \n","- The classes are really unbalanced. We should find a way to compesate for this. A common approach in these cases is to give a different weight to the losses depending on the target value (rare labels get higher loss)\n","- The BIO tagging system was not used properly, we should add further preprocessing to be sure that the samples we tagged correctly"]},{"cell_type":"markdown","metadata":{"id":"-QXsI0jumzPu"},"source":["We can play a bit with the model directly.\n","\n","Let's define a function to compute the predictions give a sentence. We will use the NLTK tokenizer to split the sentence into word tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1781,"status":"ok","timestamp":1680621062287,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"nA2bJ-Cha3tb","outputId":"a0c26704-0da3-4b6a-ffa6-6b7def256953"},"outputs":[],"source":["import nltk\n","nltk.download('punkt')\n","\n","from nltk.tokenize import word_tokenize\n","\n","def predict(sample):\n","    # Tokenize sample\n","    tokenized_sample = word_tokenize(sample)\n","    # Create an input tensor with all zero values\n","    input_embeds = np.zeros((1, len(tokenized_sample), 50))\n","    # Fill the tensor and the matrix\n","    for i, token in enumerate(tokenized_sample):\n","        # Manage missing tokens in vocabulary\n","        if token.lower() in we_model:\n","            input_embeds[0, i] = we_model[token.lower()]\n","    # Convert to PyTorch tensor\n","    input_embeds = torch.tensor(input_embeds, dtype=torch.float, device=device)\n","    # Run model over input\n","    logits = lstm(embeds)\n","    # Get predictions as the index corresponding to the highest logit score\n","    pred_lbl = torch.argmax(logits, dim=-1)\n","    # Decode labels\n","    pred_labels = ner_le.inverse_transform(pred_lbl.reshape(-1).cpu().numpy())\n","    # Group together tokens and predicted NER labels\n","    labelled_sample = [{'text': token, 'ner_tag': str(lbl)} for token, lbl in zip(tokenized_sample, pred_labels)] \n","\n","    return labelled_sample"]},{"cell_type":"markdown","metadata":{"id":"7FHvWQjQa3tb"},"source":["And now call it on a custom sample"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":967,"status":"ok","timestamp":1680621121821,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"YUSA5d6kmzgz","outputId":"1b09b8dd-0aa8-4f0e-f105-64ba7604722c"},"outputs":[],"source":["sample = \"Hello, my name is Winston Churchill and I like pizza.\"\n","\n","predict(sample)"]},{"cell_type":"markdown","metadata":{"id":"6d2-csmU02-n"},"source":["Look how our custom model mails flawlessly"]},{"cell_type":"markdown","metadata":{"id":"C_jDJ6rxUEgP"},"source":["### Defining and training the RNN model for POS-tagging\n","\n","You can do this at home to start getting familiar with PyTorch and RNNs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xZzejzJYUSAE"},"outputs":[],"source":["# TODO"]},{"cell_type":"markdown","metadata":{"id":"dDHo75GQgekV"},"source":["## Text Classification with a Recurrent Neural Network\n","\n","In this last section of the notebook I will run through a quick example of using a Bidirectional LSTM (Long Short-term Memory) network for text classification. \n","- RNNs extend embedding-based classification of text by taking word-order into account. They were, until relatively recently, the state-of-the-art when it came to training text classifiers.\n","- Tensorflow is sophisticated toolkit for building Deep Neural Network models. We will use it to build the model. The tutorial follows mostly this Tensorflow tutorial: https://www.tensorflow.org/tutorials/text/text_classification_rnn\n","    - Tensorflow is to deep learning learning what Java is to programming (joking...?)\n"]},{"cell_type":"markdown","metadata":{"id":"u16CK7FTIwB1"},"source":["### Data preparation"]},{"cell_type":"markdown","metadata":{"id":"t58f_I_8lykt"},"source":["First let's load the Twitter dataset we used in the second session:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1932,"status":"ok","timestamp":1680616317996,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"sjT5uSDM-198","outputId":"b1bcb572-200b-4ce5-c666-d1ba15879d2c"},"outputs":[],"source":["import nltk\n","nltk.download('twitter_samples')\n","\n","from nltk.corpus import twitter_samples\n","positive_tweets = twitter_samples.strings('positive_tweets.json')\n","negative_tweets = twitter_samples.strings('negative_tweets.json')"]},{"cell_type":"markdown","metadata":{"id":"eD1xrLckmOgk"},"source":["Remove emoticons from the positive and negative examples:"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1680616317997,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"ZdoAOyvAmjjo"},"outputs":[],"source":["import re \n","emoticon_regex = '(\\:\\w+\\:|\\<[\\/\\\\]?3|[\\(\\)\\\\\\D|\\*\\$][\\-\\^]?[\\:\\;\\=]|[\\:\\;\\=B8][\\-\\^]?[3DOPp\\@\\$\\*\\\\\\)\\(\\/\\|])(?=\\s|[\\!\\.\\?]|$)'\n","positive_tweets_noemoticons = [re.sub(emoticon_regex,'',tweet) for tweet in positive_tweets]\n","negative_tweets_noemoticons = [re.sub(emoticon_regex,'',tweet) for tweet in negative_tweets]"]},{"cell_type":"markdown","metadata":{"id":"mBYSfDdNnyjt"},"source":["And create the examples and labels as we did before. This time we will use numeric labels (0,1) instead of text labels ('negative','positive'), since the deep learning library we will use requires numeric class labels."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1680616317998,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"-m_yGUqZb_eC"},"outputs":[],"source":["tweets_x = positive_tweets_noemoticons + negative_tweets_noemoticons\n","tweets_y = [1]*len(positive_tweets) + [0]*len(negative_tweets)"]},{"cell_type":"markdown","metadata":{"id":"0NMm42BXoFPr"},"source":["And again, split the data into training, validation and test:"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1680616317999,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"GWFm2EAUEttp"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","temp_x, test_x, temp_y, test_y = train_test_split(tweets_x, tweets_y, test_size=0.2)\n","train_x, valid_x, train_y, valid_y = train_test_split(temp_x, temp_y, test_size=0.2)"]},{"cell_type":"markdown","metadata":{"id":"78Up263koMI9"},"source":["Now that we have the training and validation data prepared, we can import the Tensorflow library, and use it to load the training and validaton datasets into the tensorflow format. Note that:\n","- Tensorflow comes installed on Google Colab. \n","- If you run this notebook on your own machine you will need to first install tensorflow using '!pip install'"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5876,"status":"ok","timestamp":1680616323868,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"Tryj01SOHdQD"},"outputs":[],"source":["import tensorflow as tf\n","train_tf = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n","valid_tf = tf.data.Dataset.from_tensor_slices((valid_x, valid_y))"]},{"cell_type":"markdown","metadata":{"id":"Bns4PMHlosKG"},"source":["Training will run on *batches* of the data at a time, so we need to create them.\n","- We first use the shuffle command to randomise the order of the training data. (The buffer-size limits the number of instances loaded into memory when shuffling and is only for efficiency -- you could remove it.)\n","- We then create the batches. Each batch will contain 64 examples.\n","- The validation data needs to have the same format as the training data, so we batch it too."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1680616323869,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"lYHJ3N_9Fk4M"},"outputs":[],"source":["train_dataset = train_tf.shuffle(buffer_size=10000).batch(batch_size=64).prefetch(tf.data.AUTOTUNE)\n","valid_dataset = valid_tf.batch(batch_size=64).prefetch(tf.data.AUTOTUNE)"]},{"cell_type":"markdown","metadata":{"id":"W_kUXbOTp_E5"},"source":["Let's have a look at the first batch in the training data. It consists of:\n","- an array of strings (tweets)\n","- an array of binary values (class labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1680616323869,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"iO4o9OCmpjHP","outputId":"9ea0f65e-f130-4f76-a5bd-82abc43aeaf8"},"outputs":[],"source":["for batch in train_dataset.take(1):\n","  print(batch)"]},{"cell_type":"markdown","metadata":{"id":"Kecw1hDHqDwq"},"source":["Now that we have the text data in the format required, we can vectorize it. We will need to make use a specific text vectorization module from tensorflow to do this.\n","- We first limit the vocabulary of the vectorizer to 5000,\n","- then extract only the text portion of the training dataset,\n","- and finally fit the vectorizer to the text using the 'adapt' method:"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1054,"status":"ok","timestamp":1680616324917,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"jWBSlNHYH63Q"},"outputs":[],"source":["from tensorflow.keras.layers import TextVectorization\n","vectorizer = TextVectorization(max_tokens=5000)\n","train_text = train_dataset.map(lambda text, label: text)\n","vectorizer.adapt(train_text)"]},{"cell_type":"markdown","metadata":{"id":"zxBb8rBmrncY"},"source":["Let's print out the first tokens form the vocabulary:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":305,"status":"ok","timestamp":1680616335270,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"U4mx6bPwIHcs","outputId":"e1d82cb1-8422-4095-a208-93831c58bf99"},"outputs":[],"source":["vocab = vectorizer.get_vocabulary()\n","vocab[:100]"]},{"cell_type":"markdown","metadata":{"id":"Ew9vtoMusC5x"},"source":["Note that the first two tokens in the vocabulary are the empty token '', and the unknown token '[UNK]'. The latter is used to mask out-of-vocabulary tokens in the text\n","\n","We can now use the vectorizer to encode a tweet:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":342,"status":"ok","timestamp":1680616361718,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"9T7q-VGpINji","outputId":"a1b18da3-73ec-4b61-a06d-3017b1be8e1b"},"outputs":[],"source":["text = 'This is my first tweet! It contains one out-of-vocabulary term. Any suggestions for extending this tweet?'\n","encoding = vectorizer([text]).numpy()[0]\n","print('Tweet:     ', text)\n","print('Encoded:   ', encoding) \n","print('Recovered: ',' '.join([vocab[i] for i in encoding]))"]},{"cell_type":"markdown","metadata":{"id":"Fnpb08OAysG0"},"source":["Note that the vectorizer is not turning the text into a single vector, but is simply replacing the vocabulary words by their indices. If a word is not present in the dictionary it is replaced by the unknown token."]},{"cell_type":"markdown","metadata":{"id":"adhzBr8gxol6"},"source":["Let's have a look at some actual examples from the dataset, printing out the first 6 tweets:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":343,"status":"ok","timestamp":1680616366040,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"CVhxZQhlb5pb","outputId":"1a094a02-5e1b-4a2a-baf2-425bb5a1b677"},"outputs":[],"source":["for text in batch[0][:6].numpy():\n","    encoding = vectorizer([text]).numpy()[0]\n","    print('Tweet:     ', text.decode(\"utf-8\"))\n","    print('Encoded:   ', encoding) \n","    print('Recovered: ',' '.join([vocab[i] for i in encoding]))\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"AVu5mm0BlnIU"},"source":["### Defining the RNN model\n","\n","Now we can define the model, which contains four layers: \n","- an input embedding layer which produces word embeddings of size 64\n","- a bidirectional LSTM layer\n","- 2 dense (aka fully connected) layers that maps the 2 embedding vectors (of size 64) produced by the bidirectional LSTM down to a single neuron   \n","\n","This constitutes a relatively standard basic RNN architecture. (The details of why these specific components are chosen is beyond the scope of this tutorial.)  \n","\n","Once the model has been defined it is compiled in the following step: "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2012,"status":"ok","timestamp":1680616395899,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"NkBOSHb8IdNq"},"outputs":[],"source":["model = tf.keras.Sequential([\n","    vectorizer,                       \n","    tf.keras.layers.Embedding(input_dim=len(vectorizer.get_vocabulary()), output_dim=64, mask_zero=True), \n","    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n","    tf.keras.layers.Dense(64, activation='relu'),\n","    tf.keras.layers.Dense(1)\n","])\n","model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'], optimizer=tf.keras.optimizers.Adam(1e-4))"]},{"cell_type":"markdown","metadata":{"id":"dZ3xHUUdvdOp"},"source":["Fit the model by running it for 10 epochs (iterations over the training data).\n","- Note that we provide it with both the training dataset and the validation dataset:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":83742,"status":"ok","timestamp":1680616483776,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"I8QbNIKxI375","outputId":"cf37b3d0-69be-4cc3-ea3f-cb062aa8b7e3"},"outputs":[],"source":["model.fit(train_dataset, epochs=10, validation_data=valid_dataset, validation_steps=20)"]},{"cell_type":"markdown","metadata":{"id":"6e-Xzgsr-3Pl"},"source":["Once we've trained the model we can check the final accuracy on the validation data:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1757,"status":"ok","timestamp":1680616491872,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"cB34Jys-I7p2","outputId":"22f645de-1a8d-4e2f-c36d-cc3c862e16a2"},"outputs":[],"source":["valid_loss, valid_acc = model.evaluate(valid_dataset)\n","\n","print('Validation Loss: {}'.format(valid_loss))\n","print('Validation Accuracy: ',valid_acc)"]},{"cell_type":"markdown","metadata":{"id":"1sCKn20yCLDs"},"source":["We can have a look at the predictions from the model:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2991,"status":"ok","timestamp":1680616501371,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"EZtp5zCvgoVc","outputId":"f1c23b2a-02be-4037-a3bb-1ac81164db6c"},"outputs":[],"source":["tweets = []\n","tweets.append('I can\\'t believe how much fun I\\'m having learning to train a text classifier with a bidirectional LSTM!')\n","tweets.append('I am really confused. I want my mommy.')\n","tweets.append('The internet connection has been pretty annoying today!')\n","tweets.append('They just played my favourite song on the radio.')\n","tweets.append(\"I don't like going to the dentist.\")\n","tweets.append('I am so happy today!')\n","tweets.append('I am so unhappy today!')\n","\n","predictions = model.predict(tweets)\n","\n","for i in range(len(tweets)):\n","  print('tweet: ',tweets[i])\n","  encoding = vectorizer([tweets[i]]).numpy()[0]\n","  print('encoded as: ',' '.join([vocab[j] for j in encoding]))\n","  print('predicted value: ', predictions[i][0])\n","  print('predicted label: ', 'negative' if (predictions[i]<0) else 'positive')\n","  print()"]},{"cell_type":"markdown","metadata":{"id":"wvAe7kWdCPpv"},"source":["And calculate the usual evaluation metrics:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"executionInfo":{"elapsed":2529,"status":"ok","timestamp":1680616537070,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"m8FABFCi693C","outputId":"c4084ac7-f724-432e-cbea-ae8ef4be6304"},"outputs":[],"source":["pred_y = [0 if (pred < 0) else 1 for pred in model.predict(valid_x)]\n","\n","from sklearn.metrics import accuracy_score\n","print('accuracy: '+ str(accuracy_score(pred_y, valid_y)))\n","\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","cmd = ConfusionMatrixDisplay(confusion_matrix(valid_y, pred_y,normalize='true'), display_labels=['negative', 'positive'])\n","cmd.plot()"]},{"cell_type":"markdown","metadata":{"id":"6hNoR7FzIVSW"},"source":["Finally, let's print out the model summary to get an understanding of the number of parameters in the model:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":410,"status":"ok","timestamp":1680616553008,"user":{"displayName":"Vincenzo Scotti","userId":"11083671475743415769"},"user_tz":-120},"id":"msGvq6XA_qxP","outputId":"dd7b0756-f960-430d-d2fb-ab606f316082"},"outputs":[],"source":["print(model.summary())"]},{"cell_type":"markdown","metadata":{"id":"v8yHHWsbJjtm"},"source":["Most of the parameters are used to define the embeddiing, then the LSTMs. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lrHVkXHzJrQM"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"017463dc321c43b89278a5cf4888444f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0974d75f27f54ec6a6b2178bf1b9744d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a2b7b8947b3496da3c4ce8377573368":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c8c937870834179abeb572df4d0d552":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8899fb38e0d14cd29281285e3a42b51b","max":1167937,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bcd8f46d9f414f429f81d1df02838d51","value":1167937}},"0cba6e75539b4d19b8d570a404497b51":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14444e6b397d4fe484074bff601312c5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a178b1869b774ba687649b344e804478","placeholder":"​","style":"IPY_MODEL_0a2b7b8947b3496da3c4ce8377573368","value":" 22.6M/22.6M [00:00&lt;00:00, 63.2MB/s]"}},"194b8a513203433b8e0701150f36a41c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5446764ef1bb4dec8356ccba6398a582","max":22585138,"min":0,"orientation":"horizontal","style":"IPY_MODEL_72a207a566aa40e492ae78bbcb19c469","value":22585138}},"1cff1ebe875e4d6c9aee998441263e3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_894eed98e66145f6b2119a5dabc28aed","max":29911,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ea90a0d682f48fc9c19e121d052b2c3","value":29911}},"1f3857e7f59e4c07a581bced61f6e91b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fd6ab8bdf494cea8a98a1f25b8175cf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a5a57a23d8f4a9ab96db2abb52b486f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ea90a0d682f48fc9c19e121d052b2c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"33f31ff150b0454c87265dc1b0ee9a66":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_727cf550c6304701a87e692f987d3bb2","placeholder":"​","style":"IPY_MODEL_d19c8ea288714972b80177dbb411582f","value":"Downloading https://huggingface.co/stanfordnlp/stanza-it/resolve/v1.5.0/models/forward_charlm/conll17.pt: 100%"}},"34835e0f6b804e8c92ac149286b94d7f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3539ff61c6e04ab09eeec4964ce1c9db":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a6cda4550814d688c1f933f586844f8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c1f5a07455c7439e8fa5e21e398fa2b0","IPY_MODEL_1cff1ebe875e4d6c9aee998441263e3f","IPY_MODEL_e3329f86180a4f878dbc8863e059f2a1"],"layout":"IPY_MODEL_72901170aee540128f442465cced481d"}},"3d63c623e998446483d44389f685abe2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42787d1154914368b031860461fd09c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"45a25e6c154b468b9d7d6fa785cbaae2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"46649e92e7194805962ec36c97057c2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2f6bb3a7f904b2ab12c12168d67dd6e","placeholder":"​","style":"IPY_MODEL_8c5451b5e1ad475f99ede13833a328f7","value":" 649k/649k [00:00&lt;00:00, 17.8MB/s]"}},"482a1ffafc894b399dee4e30a68c0cd0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50848de518c14419a350027e54032cdf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d3a38c4c27284966abdb4994d20f5363","IPY_MODEL_afb80bae23454de595e08d937eda4a6b","IPY_MODEL_ef5f36be5fbc4b9182137df1ba12ce3f"],"layout":"IPY_MODEL_a8ed2c31164447159d3ac543f08a91ee"}},"51e99a99171b4e2db399fd618bf8c0c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_942674ea474641cd89d3f0fec140024b","IPY_MODEL_5bad16cc99114049a8cc859a338fd6c1","IPY_MODEL_fe5b7dac4b714bb2b771b0ff0a3e5ddc"],"layout":"IPY_MODEL_6cf1079ca2484cab8bff9c6f79227477"}},"5446764ef1bb4dec8356ccba6398a582":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bad16cc99114049a8cc859a338fd6c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0fe780f411f432eae0dbf82e4717e2a","max":54987821,"min":0,"orientation":"horizontal","style":"IPY_MODEL_859dfd0aa4574ea4be667133817677f6","value":54987821}},"61881593408345b298c62a0a5634b69f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6cf1079ca2484cab8bff9c6f79227477":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70b3d8de3bde4f5a8b331fbe11737a02":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"726cf2f1a4b340af9be3d6549825eb3b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"727cf550c6304701a87e692f987d3bb2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72901170aee540128f442465cced481d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72a207a566aa40e492ae78bbcb19c469":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7729d46c99aa4037998116e202acbb72":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7b402deff2894db6b632e2ac9ee647cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfd655af8757410d922efef737f11c28","placeholder":"​","style":"IPY_MODEL_9ac782a738f242aaaf2caa1b98553552","value":"Downloading https://huggingface.co/stanfordnlp/stanza-it/resolve/v1.5.0/models/backward_charlm/conll17.pt: 100%"}},"808fb5dffc824cd69c2380e9be854778":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7b402deff2894db6b632e2ac9ee647cd","IPY_MODEL_194b8a513203433b8e0701150f36a41c","IPY_MODEL_e72c523335444386b35c398225e7b770"],"layout":"IPY_MODEL_482a1ffafc894b399dee4e30a68c0cd0"}},"859dfd0aa4574ea4be667133817677f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8899fb38e0d14cd29281285e3a42b51b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"894eed98e66145f6b2119a5dabc28aed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c5451b5e1ad475f99ede13833a328f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92d6a2c55a404f7680c8596579d9c1dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"942674ea474641cd89d3f0fec140024b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0b954a656e0426f82fa67183b1ea28c","placeholder":"​","style":"IPY_MODEL_cc60fc78d637456188ee49c4291eaa90","value":"Downloading https://huggingface.co/stanfordnlp/stanza-it/resolve/v1.5.0/models/ner/fbk.pt: 100%"}},"9ac782a738f242aaaf2caa1b98553552":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b82d939d6634a07aca08d476d2b5326":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e57c7471dc914699a0329e36c2d46bce","placeholder":"​","style":"IPY_MODEL_92d6a2c55a404f7680c8596579d9c1dc","value":"Downloading https://huggingface.co/stanfordnlp/stanza-it/resolve/v1.5.0/models/tokenize/combined.pt: 100%"}},"9dc5e6a9f35a46adba95ab3a22e65c1f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d63c623e998446483d44389f685abe2","max":649184,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d1aa62b7121b4db28380780b5abc7bfe","value":649184}},"9e607eaa7047442aae90cfae83039438":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9b82d939d6634a07aca08d476d2b5326","IPY_MODEL_9dc5e6a9f35a46adba95ab3a22e65c1f","IPY_MODEL_46649e92e7194805962ec36c97057c2a"],"layout":"IPY_MODEL_c9bde1772e004b4186caa582e33463d0"}},"9fa5e3d27b0e4120a3e4ab54b4132a3e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a178b1869b774ba687649b344e804478":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a84b76d7ccbe4172bc191d3bb23bf615":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8ed2c31164447159d3ac543f08a91ee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa4729f8e6fd4552ad0d30fab533fd4c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afb80bae23454de595e08d937eda4a6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7cae6a5940744e3af1f3f13b44ff41c","max":106875579,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7729d46c99aa4037998116e202acbb72","value":106875579}},"bcd8f46d9f414f429f81d1df02838d51":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c1f5a07455c7439e8fa5e21e398fa2b0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70b3d8de3bde4f5a8b331fbe11737a02","placeholder":"​","style":"IPY_MODEL_d9fe139593184666858f38d24c07f93b","value":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json: "}},"c2f6bb3a7f904b2ab12c12168d67dd6e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6f28ff3a8244a729b3fe9901c07559b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9bde1772e004b4186caa582e33463d0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca95de1a2337440a82a62364d29648f3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e2dd95f03f6149e38457c66a0258d533","IPY_MODEL_0c8c937870834179abeb572df4d0d552","IPY_MODEL_f5e7e60c8ddb4c42918459b494543e35"],"layout":"IPY_MODEL_ea1d40350be84b848d3ba02cf9abfe0e"}},"cc60fc78d637456188ee49c4291eaa90":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d19c8ea288714972b80177dbb411582f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1aa62b7121b4db28380780b5abc7bfe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d3a38c4c27284966abdb4994d20f5363":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0974d75f27f54ec6a6b2178bf1b9744d","placeholder":"​","style":"IPY_MODEL_61881593408345b298c62a0a5634b69f","value":"Downloading https://huggingface.co/stanfordnlp/stanza-it/resolve/v1.5.0/models/pretrain/combined.pt: 100%"}},"d4513a2cde814f5d874800f5e222b4ab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7cae6a5940744e3af1f3f13b44ff41c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d93024b54175448983d17ffb9cd50f6a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_33f31ff150b0454c87265dc1b0ee9a66","IPY_MODEL_f66d7bb7a7f34ee99aac3a6862b4b00a","IPY_MODEL_14444e6b397d4fe484074bff601312c5"],"layout":"IPY_MODEL_1fd6ab8bdf494cea8a98a1f25b8175cf"}},"d9fe139593184666858f38d24c07f93b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dfd655af8757410d922efef737f11c28":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0fe780f411f432eae0dbf82e4717e2a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2dd95f03f6149e38457c66a0258d533":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a84b76d7ccbe4172bc191d3bb23bf615","placeholder":"​","style":"IPY_MODEL_45a25e6c154b468b9d7d6fa785cbaae2","value":"Downloading https://huggingface.co/stanfordnlp/stanza-it/resolve/v1.5.0/models/mwt/combined.pt: 100%"}},"e3329f86180a4f878dbc8863e059f2a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f3857e7f59e4c07a581bced61f6e91b","placeholder":"​","style":"IPY_MODEL_9fa5e3d27b0e4120a3e4ab54b4132a3e","value":" 200k/? [00:00&lt;00:00, 8.11MB/s]"}},"e57c7471dc914699a0329e36c2d46bce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e72c523335444386b35c398225e7b770":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa4729f8e6fd4552ad0d30fab533fd4c","placeholder":"​","style":"IPY_MODEL_0cba6e75539b4d19b8d570a404497b51","value":" 22.6M/22.6M [00:00&lt;00:00, 52.3MB/s]"}},"ea1d40350be84b848d3ba02cf9abfe0e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef5f36be5fbc4b9182137df1ba12ce3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4513a2cde814f5d874800f5e222b4ab","placeholder":"​","style":"IPY_MODEL_726cf2f1a4b340af9be3d6549825eb3b","value":" 107M/107M [00:00&lt;00:00, 205MB/s]"}},"f0b954a656e0426f82fa67183b1ea28c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5e7e60c8ddb4c42918459b494543e35":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3539ff61c6e04ab09eeec4964ce1c9db","placeholder":"​","style":"IPY_MODEL_34835e0f6b804e8c92ac149286b94d7f","value":" 1.17M/1.17M [00:00&lt;00:00, 24.8MB/s]"}},"f66d7bb7a7f34ee99aac3a6862b4b00a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_017463dc321c43b89278a5cf4888444f","max":22585136,"min":0,"orientation":"horizontal","style":"IPY_MODEL_42787d1154914368b031860461fd09c4","value":22585136}},"fe5b7dac4b714bb2b771b0ff0a3e5ddc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a5a57a23d8f4a9ab96db2abb52b486f","placeholder":"​","style":"IPY_MODEL_c6f28ff3a8244a729b3fe9901c07559b","value":" 55.0M/55.0M [00:01&lt;00:00, 43.9MB/s]"}}}}},"nbformat":4,"nbformat_minor":0}
