{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3302ac4-3ac7-4e3a-9bd7-c88a5565179a",
   "metadata": {},
   "source": [
    "# Semantic Search\n",
    "\n",
    "This notebook shows hot to make use of pre-trained Transformer models for document embeddings.\n",
    "These models are trained using *supervised* or *unsupervised* approaches to encode text at sentence-level, paragraph-level or even entire document-level.\n",
    "They can be applied to many different tasks\n",
    "- Semantic similarity\n",
    "- Paraphrase detection\n",
    "- Natural Langage Inference\n",
    "- Question Answering\n",
    "- Information retreival\n",
    "- Clustering\n",
    "\n",
    "Most of the material is based on the tuorial and examples on [Sentence Transformers](https://www.sbert.net/docs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f37bfa-3a06-4cf0-9c51-ea39d7874703",
   "metadata": {},
   "source": [
    "## Prepare environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe8340a-44ff-4166-b3b8-3c79c8049e9e",
   "metadata": {},
   "source": [
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c0629c-1820-4b1f-a4ee-1597e459f3bd",
   "metadata": {},
   "source": [
    "## Sentence transformer models\n",
    "\n",
    "https://www.sbert.net/examples/applications/semantic-search/README.html\n",
    "\n",
    "https://www.sbert.net/examples/applications/retrieve_rerank/README.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87afda88-dc16-4f73-b48e-95458a7ff69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dde3423-64dd-4361-a064-45f8005411a3",
   "metadata": {},
   "source": [
    "#### Embedding text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bffafc0-4bbc-4b61-b283-0aac9b383e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'A man is eating food.',\n",
    "    'A man is eating a piece of bread.',\n",
    "    'The girl is carrying a baby.',\n",
    "    'A man is riding a horse.',\n",
    "    'A woman is playing violin.',\n",
    "    'Two men pushed carts through the woods.',\n",
    "    'A man is riding a white horse on an enclosed ground.',\n",
    "    'A monkey is playing drums.',\n",
    "    'A cheetah is running behind its prey.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c39e70-efb6-41c8-b659-193384d3a8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "corpus_embeddings.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af4a5d-c00d-4f9b-970e-fe016b1d356c",
   "metadata": {},
   "source": [
    "Speed-up by by nomalising the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219db30f-f14a-4157-a88a-402995ab8a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_embeddings = corpus_embeddings.to('cuda')\n",
    "corpus_embeddings = util.normalize_embeddings(corpus_embeddings)\n",
    "\n",
    "query_embeddings = query_embeddings.to('cuda')\n",
    "query_embeddings = util.normalize_embeddings(query_embeddings)\n",
    "hits = util.semantic_search(query_embeddings, corpus_embeddings, score_function=util.dot_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a4e659-4596-4e09-8a39-7408db102043",
   "metadata": {},
   "source": [
    "#### Visualising the embedding space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b2049d-7ad6-4c4c-b04f-c4fd1f51cfb7",
   "metadata": {},
   "source": [
    "#### Cosine similarity between embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ec6492-0f50-47b3-9949-e6a3968c5087",
   "metadata": {},
   "source": [
    "We can compute the similarity of embedding pairs in our corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c16f18-ed0b-42bb-923f-e4eff5448c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = util.cos_sim(corpus_embeddings, corpus_embeddings)[0].reshape(corpus_embeddings.size(1), corpus_embeddings.size(1))\n",
    "similarity_matrix.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ae9259-929d-45ad-8ce3-255fb94ebe79",
   "metadata": {},
   "source": [
    "### Cross-encoder\n",
    "\n",
    "https://www.sbert.net/examples/applications/cross-encoder/README.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7ab06e-aaa1-4d13-81cb-10a38d542225",
   "metadata": {},
   "source": [
    "## Semantic search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d8fd91-bf88-49e5-a624-15e2d0dcff7d",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d654093-19e4-40ce-afb8-02bf9e574590",
   "metadata": {},
   "source": [
    "### Computing document-query similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbb2973-a892-445e-a1ef-af047cd2fbda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfc5ffa-0429-4de9-86a9-c5e217f8d05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    'A man is eating pasta.', \n",
    "    'Someone in a gorilla costume is playing a set of drums.', \n",
    "    'A cheetah chases prey on across a field.'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0c8c7b-10cd-415f-a5e2-15d54d347fe5",
   "metadata": {},
   "source": [
    "Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2867da-88fc-4b1b-bb1e-5cdcbcb5e170",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_k = min(5, len(corpus))\n",
    "for query in queries:\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "    cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "        print(corpus[idx], \"(Score: {:.4f})\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f329dd-aa9b-4ee3-8a19-c104f6814892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22b91088-565b-4bf3-805c-a917ac6969b8",
   "metadata": {},
   "source": [
    "#### Cross-encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1036f0e-f2c9-4a2e-bb73-36bc3d0279a4",
   "metadata": {},
   "source": [
    "### Approximated Nearest Neighbor search\n",
    "\n",
    "When we use a bi-encoder model, we can pre-compute the embeddings in our data set and index them to speed-up the search.\n",
    "There are techniques for Approximate Nearest Neighbor (ANN), which use clustering to index the embedding space and speed-up the search process.\n",
    "\n",
    "Note that this is not applicable to cross-encoder models, which encode document and query together.\n",
    "\n",
    "Sentence transformers support different libraries for ANN:\n",
    "- [HNSWLIB](https://github.com/nmslib/hnswlib/)\n",
    "- [Annoy](https://github.com/spotify/annoy)\n",
    "- [FAISS](https://github.com/spotify/annoy)\n",
    "\n",
    "Let's try indexing with **HNSWLIB** and compare search time\n",
    "\n",
    "https://www.sbert.net/examples/applications/semantic-search/README.html#approximate-nearest-neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7146c4c7-4dea-4283-bd69-764001ef50dc",
   "metadata": {},
   "source": [
    "### Re-ranking\n",
    "\n",
    "Cross-encoder models empirically yield better results, but are slow at inference.\n",
    "Bi-encoder models, on the other side, are less precise, but are also faster at inference.\n",
    "\n",
    "We can take advantage of both: We can do a first search with bi-encoder models and then re-rank the top-$k$ results with a cross-encoder.\n",
    "We call this approach *retrieve and re-rank*.\n",
    "\n",
    "https://www.sbert.net/examples/applications/retrieve_rerank/README.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc61d40-5b6d-4dc4-b67b-9c275f980366",
   "metadata": {},
   "source": [
    "## Question answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa1dc5e-f76a-4618-86dd-b636c862065d",
   "metadata": {},
   "source": [
    "### QA data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd01742-fd61-4a1d-a954-24883e8a7196",
   "metadata": {},
   "source": [
    "#### Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc308a10-5276-4dc5-87c5-e16f812d3935",
   "metadata": {},
   "source": [
    "#### Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f56d23f-7a8e-4adf-aeea-edcc4382d676",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a33d97-0a96-4853-abf7-4f42bc181be2",
   "metadata": {},
   "source": [
    "### Search response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ba866b-244d-4273-9119-f9ad31d80a5b",
   "metadata": {},
   "source": [
    "## Retrieval-based chatbots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a54170-251d-4a23-9013-a9634b4bd046",
   "metadata": {},
   "source": [
    "### Dialogue data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723b0ec3-3d42-4e0c-ad12-26369109c15f",
   "metadata": {},
   "source": [
    "#### Load "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e678963-290c-4ed1-94c2-7e56d9a7fbed",
   "metadata": {},
   "source": [
    "#### Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aab601-e10a-40cf-a88f-9918a6d0f786",
   "metadata": {},
   "source": [
    "### Search for response\n",
    "\n",
    "We can appraoch the problem of searching for a response in two ways:\n",
    "1. Search for a similar context (i.e., last message in dialogue history) and return the associated response.\n",
    "2. Search for a response as the most similar messagr to the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf31044c-404b-4069-bb24-3820dc2269a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "614a808a-c7f1-4fdd-91e8-443a95720a03",
   "metadata": {},
   "source": [
    "Let's try chatting with our retreival system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55395e14-1647-4801-a7ef-02489fd13b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Press [Ctrl-C] to stop\")\n",
    "# Initialise dialogue history\n",
    "dialogue_history = [\"Hello, how are you?\"]\n",
    "print(f\"Chatbot: {dialogue_hisotry[0]}\")\n",
    "# Keep talking until stop\n",
    "running = True\n",
    "while running:\n",
    "    try:\n",
    "        # Read user message\n",
    "        message = input(\"User: \")\n",
    "        # Append message to dialogue history\n",
    "        dialogue_history.append(message)\n",
    "        # Search for a chatbot response\n",
    "        response = ...\n",
    "        # Append chatbot response to dialogue history\n",
    "        dialogue_history.append(message)\n",
    "        # Print chatbot response\n",
    "        print(f\"Chatbot: {response}\")\n",
    "    except KeyboardInterrupt():\n",
    "        running = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
